{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8793815,"sourceType":"datasetVersion","datasetId":5287475},{"sourceId":8997919,"sourceType":"datasetVersion","datasetId":5420015},{"sourceId":9060560,"sourceType":"datasetVersion","datasetId":5463941},{"sourceId":9126515,"sourceType":"datasetVersion","datasetId":5509963},{"sourceId":9180260,"sourceType":"datasetVersion","datasetId":5548621},{"sourceId":9856028,"sourceType":"datasetVersion","datasetId":6048379},{"sourceId":9856057,"sourceType":"datasetVersion","datasetId":6048401}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install necessary Libraries","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install -U langchain-community\n!pip install sentence_transformers\n!pip install pinecone-client\n!pip install pinecone-client[grpc]\n!pip install nltk\n!pip install beautifulsoup4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:34:55.321112Z","iopub.execute_input":"2024-12-05T16:34:55.321481Z","iopub.status.idle":"2024-12-05T16:35:54.301745Z","shell.execute_reply.started":"2024-12-05T16:34:55.321452Z","shell.execute_reply":"2024-12-05T16:35:54.300826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pinecone\nfrom pinecone.grpc import PineconeGRPC as Pinecone\nfrom pinecone import ServerlessSpec\n\napi_key = \"6ca3b069-c0d4-460e-8d64-9f545902b7c6\" \nenvironment = \"us-east-1\" \n\npc = Pinecone(api_key=api_key)\n\nindex_name = \"chunk-embeddings-index\"\ndimension = 768 \n\nif index_name not in pc.list_indexes().names():\n    pc.create_index(\n        name=index_name,\n        dimension=dimension,\n        metric=\"cosine\",\n        spec=ServerlessSpec(\n            cloud='aws', \n            region=environment\n        ) \n    )\n\nindex = pc.Index(index_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:35:58.443724Z","iopub.execute_input":"2024-12-05T16:35:58.444578Z","iopub.status.idle":"2024-12-05T16:35:59.284253Z","shell.execute_reply.started":"2024-12-05T16:35:58.444540Z","shell.execute_reply":"2024-12-05T16:35:59.283374Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Data, Chunk Legal Documents for Processing and setting up the vector database\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom nltk.tokenize import sent_tokenize\nfrom bs4 import BeautifulSoup\nfrom transformers import AutoTokenizer, AutoModel\nimport torch\n\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz\")\nembedding_model = AutoModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\ntext_tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n\ndef chunk_text_based_on_tokens(text, max_tokens=300):\n    sentences = sent_tokenize(text)\n    chunks = []\n    current_chunk = []\n    current_length = 0\n\n    for sentence in sentences:\n        sentence_length = len(tokenizer.tokenize(sentence))\n        if current_length + sentence_length <= max_tokens:\n            current_chunk.append(sentence)\n            current_length += sentence_length\n        else:\n            chunks.append(\" \".join(current_chunk))\n            current_chunk = [sentence]\n            current_length = sentence_length\n\n    if current_chunk:\n        chunks.append(\" \".join(current_chunk))\n\n    return chunks\n\ndef extract_sections_articles_chapters(soup):\n    sections = []\n    current_section = []\n    for element in soup.find_all(['h1', 'h2', 'h3', 'p']):\n        if element.name in ['h1', 'h2', 'h3']:\n            if current_section:\n                sections.append(\" \".join(current_section))\n                current_section = []\n            current_section.append(element.get_text())\n        else:\n            current_section.append(element.get_text())\n    if current_section:\n        sections.append(\" \".join(current_section))\n    return sections\n\ndef load_and_process_html(file_path):\n    with open(file_path, 'r', encoding='utf-8') as file:\n        html_content = file.read()\n    soup = BeautifulSoup(html_content, 'html.parser')\n    sections = extract_sections_articles_chapters(soup)\n    all_chunks = []\n    for section in sections:\n        all_chunks.extend(chunk_text_based_on_tokens(section))\n    return all_chunks\n\ndef generate_bert_embedding(text, tokenizer, model, max_length=512):\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True, \n        padding=True,\n        max_length=max_length  \n    )\n    with torch.no_grad():\n        outputs = model(**inputs)\n    embedding = outputs.last_hidden_state[:, 0, :].squeeze(0).numpy()\n    return embedding.tolist()\n\ndef upsert_chunks_to_pinecone(index, namespace, chunks, batch_size=10):\n    vectors = []\n    for i, chunk in enumerate(chunks):\n        embedding = generate_bert_embedding(chunk, text_tokenizer, embedding_model)\n        vectors.append({\n            \"id\": f\"{namespace}_id_{i}\",  \n            \"values\": embedding,\n            \"metadata\": {\"text\": chunk}  \n        })\n        \n        if len(vectors) >= batch_size:\n            index.upsert(vectors=vectors, namespace=namespace)\n            vectors = []  \n    \n    if vectors:\n        index.upsert(vectors=vectors, namespace=namespace)\n        print(f\"Upserted {len(vectors)} vectors to namespace '{namespace}'.\")\n\n\ndef process_and_upload_html(file_path, namespace):\n    print(f\"Processing file: {file_path} for namespace: {namespace}\")\n    chunks = load_and_process_html(file_path) \n    upsert_chunks_to_pinecone(index, namespace, chunks)  \n\nhtml_files_and_namespaces = {\n    'gdpr': '/kaggle/input/spanish-laws/spanish_gdpr.html',\n    'ai_act': '/kaggle/input/spanish-laws/spanish_AI_act.html',\n    'dma': '/kaggle/input/spanish-laws/spanish_dma.html',\n    'dsa': '/kaggle/input/spanish-laws/spanish_dsa.html'\n}\nfor namespace, file_path in html_files_and_namespaces.items():\n    process_and_upload_html(file_path, namespace)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:36:01.725018Z","iopub.execute_input":"2024-12-05T16:36:01.725790Z","iopub.status.idle":"2024-12-05T16:44:09.718804Z","shell.execute_reply.started":"2024-12-05T16:36:01.725754Z","shell.execute_reply":"2024-12-05T16:44:09.717854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\ndef embed_chunks(chunks, model_name):\n    model = SentenceTransformer(model_name, device='cuda')\n    \n    embeddings = model.encode(chunks, normalize_embeddings=True)\n    \n    return embeddings\n\ndef embed_query(query, model_name):\n    model = SentenceTransformer(model_name, device='cuda')\n    query_embedding = model.encode([query], normalize_embeddings=True)\n    return query_embedding[0]\n\n\ndef process_and_store_embeddings(file_path, namespace, model_name):\n    chunks = load_and_process_html(file_path)\n    embeddings = embed_chunks(chunks, model_name)\n\n    vectors_to_upsert = [(f\"id_{namespace}_{i}\", embedding.tolist()) for i, embedding in enumerate(embeddings)]\n    index.upsert(vectors=vectors_to_upsert, namespace=law) \n\n    return index, chunks, embeddings\n\ndef query_pinecone_db(query_embedding, index, namespace, top_k=1):\n    results = index.query(vector=query_embedding, top_k=top_k, namespace=law)  \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:46:05.051069Z","iopub.execute_input":"2024-12-05T16:46:05.051763Z","iopub.status.idle":"2024-12-05T16:46:06.488405Z","shell.execute_reply.started":"2024-12-05T16:46:05.051727Z","shell.execute_reply":"2024-12-05T16:46:06.487490Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# retrieve the most relevant chunk based on testing specific queries","metadata":{}},{"cell_type":"code","source":"laws_info = {\n    'gdpr': {\n        'file_path': '/kaggle/input/spanish-laws/spanish_gdpr.html',\n        'index_name': 'index_name',\n        'query': \"¿Cómo contribuye el reglamento mencionado en el texto a garantizar la libre circulación de datos personales en la Unión Europea, y qué consideraciones se tienen en cuenta para las microempresas y las pequeñas y medianas empresas?\"\n    },\n    'ai_act': {\n        'file_path': '/kaggle/input/spanish-laws/spanish_AI_act.html',\n        'index_name': 'index_name',\n        'query': \"¿Qué importancia tiene la capacidad de inferencia en la definición de un sistema de IA según el reglamento descrito, y cómo se diferencia esta capacidad de los enfoques de programación tradicionales?\"\n    },\n    'dma': {\n        'file_path': '/kaggle/input/spanish-laws/spanish_dma.html',\n        'index_name': 'index_name',\n        'query': \"¿Cómo asegura la Comisión Europea una participación equitativa del Parlamento Europeo y el Consejo en la preparación de los actos delegados relacionados con la modificación de los anexos I, II y IV del Reglamento sobre productos de doble uso?\"\n    },\n    'dsa': {\n        'file_path': '/kaggle/input/spanish-laws/spanish_dsa.html',\n        'index_name': 'index_name',\n        'query': \"¿Cómo define el concepto de contenido ilícito el presente Reglamento, y qué ejemplos específicos se mencionan para ilustrar este concepto?\"\n    }\n}\nmodel_name = (\"dccuchile/bert-base-spanish-wwm-cased\")\n\nchunks_dict = {}\nembeddings_dict = {}\nimport time\n\nif index_name in pc.list_indexes().names():\n    print(f\"Deleting index '{index_name}'...\")\n    pc.delete_index(index_name)\n\n    print(\"Waiting for the index to be deleted...\")\n    time.sleep(5)  \n\n    if index_name not in pc.list_indexes().names():\n        print(f\"Index '{index_name}' successfully deleted.\")\n    else:\n        print(f\"Index '{index_name}' still exists, trying again...\")\n        pc.delete_index(index_name)\n        time.sleep(5) \n        if index_name not in pc.list_indexes().names():\n            print(f\"Index '{index_name}' successfully deleted on second attempt.\")\n        else:\n            print(f\"Failed to delete index '{index_name}'. Please check your Pinecone dashboard.\")\nelse:\n    print(f\"Index '{index_name}' does not exist or was already deleted.\")\n\npc.create_index(\n    name=index_name,\n    dimension=dimension,\n    metric=\"cosine\",\n    spec=ServerlessSpec(\n        cloud='aws', \n        region=environment\n    )\n)\nprint(f\"Index '{index_name}' created successfully.\")\n\nfor law, info in laws_info.items():\n    print(f\"Processing {law}...\")\n    index, chunks, embeddings = process_and_store_embeddings(info['file_path'], info['index_name'], model_name)\n    chunks_dict[law] = chunks \n    embeddings_dict[law] = embeddings\n\n    vectors_to_upsert = [(f\"{law}_id_{i}\", embedding.tolist()) for i, embedding in enumerate(embeddings)]\n    \n    try:\n        print(f\"Clearing vectors for namespace '{law}'...\")\n        index.delete(delete_all=True, namespace=law)  \n        print(f\"Namespace '{law}' cleared.\")\n    except Exception as e:\n        print(f\"Namespace '{law}' does not exist or an error occurred: {e}\")\n    \n    try:\n        print(f\"Upserting vectors for namespace '{law}'...\")\n        index.upsert(vectors=vectors_to_upsert, namespace=law)\n        print(f\"Upsert complete for namespace '{law}'.\")\n    except Exception as e:\n        print(f\"Failed to upsert vectors for namespace '{law}': {e}\")\n\nprint(\"Chunks Dict Content: \")\nfor key in chunks_dict.keys():\n    print(f\"Law: {key}, Number of Chunks: {len(chunks_dict[key])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:46:08.682603Z","iopub.execute_input":"2024-12-05T16:46:08.683297Z","iopub.status.idle":"2024-12-05T16:47:26.970520Z","shell.execute_reply.started":"2024-12-05T16:46:08.683261Z","shell.execute_reply":"2024-12-05T16:47:26.969706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for law, info in laws_info.items():\n    print(f\"\\nQuerying {law.upper()} index:\")\n    query_embedding = embed_query(info['query'], model_name)\n    print(info['query'])\n    results = query_pinecone_db(query_embedding, index, namespace=law, top_k=1)  \n    \n    if results and 'matches' in results and results['matches']:\n        retrieved_chunk_id = results['matches'][0]['id']\n        retrieved_chunk = chunks_dict[law][int(retrieved_chunk_id.split('_')[-1])]\n        print(f\"Retrieved chunk {retrieved_chunk_id.split('_')[-1]} from {law.upper()}:\")\n        print(retrieved_chunk)\n    else:\n        print(f\"No results found for {law.upper()}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:27:02.443649Z","iopub.execute_input":"2024-12-05T13:27:02.444468Z","iopub.status.idle":"2024-12-05T13:27:05.652371Z","shell.execute_reply.started":"2024-12-05T13:27:02.444414Z","shell.execute_reply":"2024-12-05T13:27:05.651474Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# measuring the relevancy of the retrieved texts and the answers","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom transformers import AutoTokenizer, AutoModel\nfrom sentence_transformers import SentenceTransformer, util\n\ntokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\nmodel = AutoModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n\nsemantic_model = SentenceTransformer('dccuchile/bert-base-spanish-wwm-cased', device='cuda')\n\ndef generate_bert_embedding(text, tokenizer, model):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    embedding = outputs.last_hidden_state[:, 0, :].numpy() \n    return embedding\n\ndef calculate_cosine_similarity(reference_embedding, retrieved_embedding):\n    return cosine_similarity(reference_embedding.reshape(1, -1), retrieved_embedding.reshape(1, -1))[0][0]\n\ndef calculate_semantic_similarity(reference_text, retrieved_text, model):\n    embeddings1 = model.encode(reference_text, convert_to_tensor=True)\n    embeddings2 = model.encode(retrieved_text, convert_to_tensor=True)\n    similarity = util.pytorch_cos_sim(embeddings1, embeddings2)\n    return similarity.item()\n\nreference_answers = {\n    'gdpr': \"Para garantizar un nivel coherente de protección de las personas físicas en toda la Unión y evitar divergencias que dificulten la libre circulación de datos personales dentro del mercado interior, es necesario un reglamento que proporcione seguridad jurídica y transparencia a los operadores económicos, incluidas las microempresas y las pequeñas y medianas empresas, y ofrezca a las personas físicas de todos los Estados miembros el mismo nivel de derechos y obligaciones exigibles y de responsabilidades para los responsables y encargados del tratamiento, con el fin de garantizar una supervisión coherente del tratamiento de datos personales y sanciones equivalentes en todos los Estados miembros, así como la cooperación efectiva entre las autoridades de control de los diferentes Estados miembros. El buen funcionamiento del mercado interior exige que la libre circulación de los datos personales en la Unión no sea restringida ni prohibida por motivos relacionados con la protección de las personas físicas en lo que respecta al tratamiento de datos personales. Con objeto de tener en cuenta la situación específica de las microempresas y las pequeñas y medianas empresas, el presente Reglamento incluye una serie de excepciones en materia de llevanza de registros para organizaciones con menos de 250 empleados. Además, alienta a las instituciones y órganos de la Unión y a los Estados miembros y a sus autoridades de control a tener en cuenta las necesidades específicas de las microempresas y las pequeñas y medianas empresas en la aplicación del presente Reglamento. El concepto de microempresas y pequeñas y medianas empresas debe extraerse del artículo 2 del anexo de la Recomendación 2003/361/CE de la Comisión (5).\",\n    'ai_act': \"Debe definirse con claridad el concepto de «sistema de IA» en el presente Reglamento y armonizarlo estrechamente con los trabajos de las organizaciones internacionales que se ocupan de la IA, a fin de garantizar la seguridad jurídica y facilitar la convergencia a escala internacional y una amplia aceptación, al mismo tiempo que se prevé la flexibilidad necesaria para dar cabida a los rápidos avances tecnológicos en este ámbito. Además, la definición debe basarse en las principales características de los sistemas de IA que los distinguen de los sistemas de software o los planteamientos de programación tradicionales y más sencillos, y no debe incluir los sistemas basados en las normas definidas únicamente por personas físicas para ejecutar automáticamente operaciones. Una característica principal de los sistemas de IA es su capacidad de inferencia. Esta capacidad de inferencia se refiere al proceso de obtención de resultados de salida, como predicciones, contenidos, recomendaciones o decisiones, que puede influir en entornos físicos y virtuales, y a la capacidad de los sistemas de IA para deducir modelos o algoritmos, o ambos, a partir de información de entrada o datos. Las técnicas que permiten la inferencia al construir un sistema de IA incluyen estrategias de aprendizaje automático que aprenden de los datos cómo alcanzar determinados objetivos y estrategias basadas en la lógica y el conocimiento que infieren a partir de conocimientos codificados o de una representación simbólica de la tarea que debe resolverse. La capacidad de inferencia de un sistema de IA trasciende el tratamiento básico de datos, al permitir el aprendizaje, el razonamiento o la modelización. El término «basado en una máquina» se refiere al hecho de que los sistemas de IA se ejecutan en máquinas.La referencia a objetivos explícitos o implícitos subraya que los sistemas de IA pueden funcionar con arreglo a objetivos definidos explícitos o a objetivos implícitos. Los objetivos del sistema de IA pueden ser diferentes de la finalidad prevista del sistema de IA en un contexto específico. A los efectos del presente Reglamento, debe entenderse por entornos los contextos en los que funcionan los sistemas de IA, mientras que los resultados de salida generados por el sistema de IA reflejan las distintas funciones desempeñadas por los sistemas de IA e incluyen predicciones, contenidos, recomendaciones o decisiones. Los sistemas de IA están diseñados para funcionar con distintos niveles de autonomía, lo que significa que pueden actuar con cierto grado de independencia con respecto a la actuación humana y tienen ciertas capacidades para funcionar sin intervención humana. La capacidad de adaptación que un sistema de IA podría mostrar tras su despliegue se refiere a las capacidades de autoaprendizaje que permiten al sistema cambiar mientras está en uso. Los sistemas de IA pueden utilizarse de manera independiente o como componentes de un producto, con independencia de si el sistema forma parte físicamente del producto (integrado) o contribuye a la funcionalidad del producto sin formar parte de él (no integrado).\",\n    'dma': \"A fin de permitir una rápida respuesta de la Unión a las circunstancias cambiantes en la evaluación de la sensibilidad de las exportaciones al amparo de las autorizaciones generales de exportación de la Unión, así como a la evolución tecnológica y comercial, deben delegarse en la Comisión los poderes para adoptar actos con arreglo al artículo 290 del Tratado de Funcionamiento de la Unión Europea (TFUE), por lo que respecta a modificar los anexos I, II y IV del presente Reglamento. Las decisiones de actualización de la lista común de productos de doble uso sujetos a controles de exportación establecida en el anexo I deben ajustarse a las obligaciones y compromisos que los Estados miembros o la Unión hayan asumido como partes en los acuerdos internacionales de no proliferación y participantes en los regímenes multilaterales de control de las exportaciones pertinentes o en virtud de la ratificación de tratados internacionales aplicables. Cuando la modificación del anexo I afecte a productos de doble uso que también están incluidos en el anexo I o IV, dichos anexos deben modificarse en consecuencia. Las decisiones de actualización de las listas comunes de productos y destinos establecidas en las secciones A a H del anexo II deben tomarse teniendo en cuenta los criterios de evaluación establecidos en el presente Reglamento. Reviste especial importancia que la Comisión lleve a cabo las consultas oportunas durante la fase preparatoria, en particular con expertos, y que esas consultas se realicen de conformidad con los principios establecidos en el Acuerdo interinstitucional de 13 de abril de 2016 sobre la mejora de la legislación (5). En particular, a fin de garantizar una participación equitativa en la preparación de los actos delegados, el Parlamento Europeo y el Consejo reciben toda la documentación al mismo tiempo que los expertos de los Estados miembros, y sus expertos tienen acceso sistemáticamente a las reuniones de los grupos de expertos de la Comisión que se ocupen de la preparación de actos delegados.\",\n    'dsa': \"A fin de alcanzar el objetivo de garantizar un entorno en línea seguro, predecible y digno de confianza, para los efectos del presente Reglamento, el concepto de «contenido ilícito» debe reflejar a grandes rasgos las normas vigentes en el entorno fuera de línea. Concretamente, el concepto de «contenido ilícito» debe definirse de manera amplia para abarcar la información relacionada con contenidos, productos, servicios y actividades de carácter ilícito. En particular, debe entenderse que dicho concepto se refiere a información, sea cual sea su forma, que sea de por sí ilícita en virtud del Derecho aplicable, como los delitos de incitación al odio o los contenidos terroristas y los contenidos discriminatorios ilícitos, o que las normas aplicables consideren ilícita por estar relacionada con actividades ilícitas. Ejemplos de ello son el intercambio de imágenes que representen abusos sexuales de menores, el intercambio ilícito no consentido de imágenes privadas, el acoso en línea, la venta de productos no conformes o falsificados, la venta de productos o la prestación de servicios que infrinjan el Derecho en materia de protección de los consumidores, el uso no autorizado de material protegido por derechos de autor, la oferta ilegal de servicios de alojamiento o la venta ilegal de animales vivos. En cambio, el vídeo de un testigo presencial de un posible delito no debe considerarse contenido ilícito por el mero hecho de que muestre un acto ilícito, cuando la grabación o difusión pública de dicho vídeo no sea ilícita con arreglo al Derecho nacional o de la Unión. En este sentido, es irrelevante tanto que el carácter ilícito de la información o actividad se derive del Derecho de la Unión o del Derecho nacional que sea conforme con el Derecho de la Unión, como la naturaleza o materia precisa del Derecho aplicable.\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:50:02.609232Z","iopub.execute_input":"2024-12-05T16:50:02.609581Z","iopub.status.idle":"2024-12-05T16:50:03.588280Z","shell.execute_reply.started":"2024-12-05T16:50:02.609554Z","shell.execute_reply":"2024-12-05T16:50:03.587317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"similarities = []\n\nfor law, info in laws_info.items():\n    print(f\"\\nQuerying {law.upper()} index:\")\n    query_embedding = embed_query(info['query'], model_name)\n    print(info['query'])\n    results = query_pinecone_db(query_embedding, index, namespace=law, top_k=1)  \n    \n    if results and 'matches' in results and results['matches']:\n        retrieved_chunk_id = results['matches'][0]['id']\n        retrieved_chunk = chunks_dict[law][int(retrieved_chunk_id.split('_')[-1])]\n        print(f\"Retrieved chunk {retrieved_chunk_id.split('_')[-1]} from {law.upper()}:\")\n        print(retrieved_chunk)\n\n        retrieved_embedding = generate_bert_embedding(retrieved_chunk, tokenizer, model)\n        reference_embedding = generate_bert_embedding(reference_answers[law], tokenizer, model)\n        cosine_sim = calculate_cosine_similarity(reference_embedding, retrieved_embedding)\n        \n        semantic_sim = calculate_semantic_similarity(reference_answers[law], retrieved_chunk, semantic_model)\n\n        similarities.append({\n            'law': law,\n            'retrieved_answer': retrieved_chunk,\n            'cosine_similarity': cosine_sim,\n            'semantic_similarity': semantic_sim\n        })\n\n        print(f\"Cosine Similarity with reference answer: {cosine_sim:.4f}\")\n        print(f\"Semantic Similarity with reference answer: {semantic_sim:.4f}\")\n        print(\"----\\n\")\n    else:\n        print(f\"No results found for {law.upper()} in the query.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:50:12.876978Z","iopub.execute_input":"2024-12-05T16:50:12.877341Z","iopub.status.idle":"2024-12-05T16:50:18.118226Z","shell.execute_reply.started":"2024-12-05T16:50:12.877311Z","shell.execute_reply":"2024-12-05T16:50:18.117437Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# setting 20 questions and their answers for each law, make embedidngs of them while making summarizations of the most relevant chunks that have beed retrieved.","metadata":{}},{"cell_type":"code","source":"integrated_questions_answers = [\n\n# Question 1 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cuál es el derecho fundamental en relación con el tratamiento de datos personales según la Carta de los Derechos Fundamentales de la Unión Europea?\",\n\n    'answer': \"La protección de las personas físicas en relación con el tratamiento de datos personales es un derecho fundamental. El artículo 8(1) de la Carta de los Derechos Fundamentales de la Unión Europea (‘la Carta’) y el artículo 16(1) del Tratado de Funcionamiento de la Unión Europea (TFUE) establecen que toda persona tiene derecho a la protección de los datos personales que le conciernen. Este Reglamento pretende contribuir a la realización de un área de libertad, seguridad y justicia y de una unión económica, al progreso económico y social, al fortalecimiento y la convergencia de las economías en el mercado interior, y al bienestar de las personas físicas.\"\n\n},\n\n# Question 1 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cuáles son los principales objetivos de la Ley de IA en relación con el desarrollo y uso de la IA en la Unión Europea?\",\n\n    'answer': \"La Ley de IA tiene como objetivo garantizar que los sistemas de IA comercializados y utilizados en la Unión sean seguros, respeten la legislación existente sobre derechos fundamentales y los valores de la Unión, y no menoscaben los derechos fundamentales. La Ley busca establecer un marco legal que aborde los riesgos que plantea la IA, en particular los sistemas de IA de alto riesgo, y mejorar la transparencia, responsabilidad y confianza en la IA, al tiempo que se promueve la innovación y la competitividad.\"\n\n},\n\n# Question 1 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Qué criterios se utilizan para definir a un 'guardián' bajo la Ley de Mercados Digitales?\",\n\n    'answer': \"Un guardián según la Ley de Mercados Digitales (DMA) se define como un proveedor de servicios de plataforma central que tiene un impacto significativo en el mercado interno, sirve como una puerta de entrada importante para que los usuarios comerciales lleguen a los usuarios finales y disfruta de una posición arraigada y duradera en el mercado. Los criterios incluyen tener una posición económica fuerte, un gran número de usuarios y control sobre un ecosistema que es difícil de contestar para otras empresas.\"\n\n},\n\n# Question 1 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cuáles son las principales responsabilidades de las plataformas en línea bajo la Ley de Servicios Digitales?\",\n\n    'answer': \"Bajo la DSA, las plataformas en línea son responsables de tomar medidas efectivas para mitigar los riesgos relacionados con el contenido ilegal, garantizar la seguridad de los usuarios y proteger los derechos fundamentales. Las plataformas deben implementar mecanismos para informar y eliminar contenido ilegal, proporcionar a los usuarios términos y condiciones claros, y establecer procesos para manejar quejas y apelaciones. Las plataformas que alcanzan un número significativo de usuarios también están obligadas a evaluar y mitigar riesgos sistémicos, como la difusión de desinformación y contenido dañino.\"\n\n},\n\n# Question 2 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cómo pretende el RGPD equilibrar el derecho a la protección de datos personales con otros derechos fundamentales?\",\n\n    'answer': \"Este Reglamento respeta todos los derechos fundamentales y observa las libertades y principios reconocidos en la Carta, tal como están consagrados en los Tratados, en particular el respeto a la vida privada y familiar, el domicilio y las comunicaciones, la protección de los datos personales, la libertad de pensamiento, conciencia y religión, la libertad de expresión e información, la libertad de empresa, el derecho a un recurso efectivo y a un juicio justo, y la diversidad cultural, religiosa y lingüística. El derecho a la protección de los datos personales debe considerarse en relación con su función en la sociedad y equilibrarse con otros derechos fundamentales, de conformidad con el principio de proporcionalidad.\"\n\n},\n\n# Question 2 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cómo propone la Ley de IA regular los sistemas de IA de alto riesgo?\",\n\n    'answer': \"La Ley de IA clasifica los sistemas de IA en función del riesgo que representan y somete a los sistemas de IA de alto riesgo a requisitos estrictos. Los sistemas de IA de alto riesgo incluyen aquellos utilizados en infraestructura crítica, educación, empleo, servicios públicos y privados esenciales, aplicación de la ley y gestión de migración, asilo y control de fronteras. Estos sistemas deben cumplir con requisitos relacionados con la gestión de riesgos, la gobernanza de datos, la documentación técnica, el mantenimiento de registros, la transparencia, la provisión de información a los usuarios, la supervisión humana, la precisión y la robustez. Los proveedores de estos sistemas deben establecer un sistema de gestión de calidad y garantizar la vigilancia continua y la supervisión posterior al mercado.\"\n\n},\n\n# Question 2 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo propone la DMA regular el comportamiento de los guardianes en los mercados digitales?\",\n\n    'answer': \"La DMA impone obligaciones específicas a los guardianes para evitar que se involucren en prácticas desleales que perjudiquen la competencia y a los consumidores. Esto incluye prohibir a los guardianes favorecer sus propios servicios sobre los de los competidores (autopreferencia), exigirles que permitan la interoperabilidad con servicios de terceros, y garantizar que no limiten injustamente el acceso a sus plataformas. Los guardianes también están obligados a proporcionar portabilidad de datos, ofrecer términos justos a los usuarios comerciales y garantizar la transparencia en sus operaciones.\"\n\n},\n\n# Question 2 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cómo pretende la DSA proteger a los usuarios del contenido ilegal en las plataformas digitales?\",\n\n    'answer': \"La DSA pretende proteger a los usuarios del contenido ilegal al requerir que las plataformas implementen mecanismos de notificación y acción, permitiendo que los usuarios informen fácilmente sobre contenido ilegal. Las plataformas deben actuar rápidamente para eliminar o deshabilitar el acceso al contenido ilegal tras recibir una notificación. La DSA también introduce obligaciones para que las plataformas cooperen con las autoridades y proporcionen informes de transparencia sobre sus actividades de moderación de contenido. Las plataformas deben tomar medidas proactivas para prevenir la difusión de contenido ilegal y garantizar que sus algoritmos no promuevan contenido dañino o ilegal.\"\n\n},\n\n# Question 3 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Qué desafíos han surgido debido a los desarrollos tecnológicos y la globalización en el contexto de la protección de datos personales?\",\n\n    'answer': \"Los desarrollos tecnológicos y la globalización han traído nuevos desafíos para la protección de los datos personales. La escala de la recopilación y el intercambio de datos personales ha aumentado significativamente. La tecnología permite a las empresas privadas y a las autoridades públicas utilizar datos personales a una escala sin precedentes para llevar a cabo sus actividades. Las personas físicas cada vez más ponen a disposición pública y global información personal. La tecnología ha transformado tanto la economía como la vida social, y debe facilitar aún más el libre flujo de datos personales dentro de la Unión y la transferencia a terceros países y organizaciones internacionales, garantizando al mismo tiempo un alto nivel de protección de los datos personales.\"\n\n},\n\n# Question 3 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Qué responsabilidades impone la Ley de IA a los proveedores de IA para garantizar prácticas éticas de IA?\",\n\n    'answer': \"Los proveedores de sistemas de IA de alto riesgo son responsables de garantizar que sus sistemas cumplan con los requisitos establecidos en la Ley. Esto incluye la obligación de realizar una evaluación de conformidad antes de comercializar el sistema, asegurar que el sistema pase por pruebas adecuadas, proporcionar instrucciones e información claras a los usuarios, implementar medidas de supervisión humana y monitorear el sistema a lo largo de su ciclo de vida. Los proveedores también deben informar de incidentes graves y fallos a las autoridades.\"\n\n},\n\n# Question 3 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cuáles son las obligaciones clave impuestas a los guardianes por la DMA?\",\n\n    'answer': \"Las obligaciones clave para los guardianes bajo la DMA incluyen prohibiciones sobre la combinación de datos personales de diferentes fuentes sin el consentimiento del usuario, restricciones sobre la preinstalación de software o aplicaciones, y requisitos para permitir que los usuarios comerciales accedan a los datos generados en su plataforma. Los guardianes deben asegurar que sus plataformas sean abiertas e interoperables con servicios de terceros y tienen prohibido usar datos no públicos de sus usuarios comerciales para competir contra ellos.\"\n\n},\n\n# Question 3 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Qué requisitos de transparencia se imponen a las plataformas en línea por la DSA?\",\n\n    'answer': \"La DSA impone requisitos extensos de transparencia a las plataformas en línea, incluyendo la obligación de publicar informes de transparencia que detallen el número de acciones de eliminación de contenido, las razones de estas acciones y los resultados de las apelaciones de los usuarios. Las plataformas también deben divulgar cómo funcionan sus sistemas de moderación de contenido y algoritmos de recomendación, incluyendo los criterios utilizados para clasificar y mostrar contenido. Los usuarios deben ser informados sobre los términos y condiciones que rigen el uso de la plataforma y cualquier cambio realizado en estos términos. Además, las plataformas deben proporcionar información clara sobre la publicidad que sirven, incluyendo la identidad de los anunciantes y los criterios de segmentación utilizados.\"\n\n},\n\n# Question 4 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cómo aborda el RGPD la transferencia de datos personales a terceros países u organizaciones internacionales?\",\n\n    'answer': \"La transferencia de datos personales a terceros países u organizaciones internacionales solo se permite cuando se cumplen las condiciones establecidas en este Reglamento, con el fin de garantizar que el nivel de protección de las personas físicas garantizado por este Reglamento no se vea menoscabado. En cualquier caso, las transferencias a terceros países y organizaciones internacionales solo pueden llevarse a cabo en pleno cumplimiento de este Reglamento. Este Reglamento se entiende sin perjuicio de los acuerdos internacionales celebrados entre la Unión y terceros países que regulen la transferencia de datos personales, incluidas las garantías adecuadas para los interesados.\"\n\n},\n\n# Question 4 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cómo aborda la Ley de IA la transparencia y la responsabilidad en los sistemas de IA?\",\n\n    'answer': \"La Ley de IA exige que los sistemas de IA, especialmente los de alto riesgo, sean transparentes y proporcionen información clara sobre su propósito, capacidades y limitaciones. Los usuarios deben poder comprender cómo se toman las decisiones por los sistemas de IA y qué datos se están procesando. La Ley exige que los sistemas de IA se diseñen con características que aseguren la responsabilidad, incluida la auditabilidad, la trazabilidad de las decisiones y la capacidad de proporcionar explicaciones de las decisiones tomadas por la IA.\"\n\n},\n\n# Question 4 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo pretende la DMA prevenir prácticas desleales en el mercado digital?\",\n\n    'answer': \"La DMA pretende prevenir prácticas desleales estableciendo reglas claras para los guardianes, incluyendo prohibiciones sobre la autopreferencia, restricciones en términos y condiciones injustas para los usuarios comerciales, y requisitos de transparencia en cómo operan. La DMA también garantiza que los guardianes no puedan usar su posición dominante para sofocar la competencia o la innovación por parte de empresas más pequeñas. La Comisión Europea tiene el poder de investigar y sancionar a los guardianes que no cumplan con estas reglas.\"\n\n},\n\n# Question 4 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cómo propone la DSA manejar la difusión de contenido dañino?\",\n\n    'answer': \"La DSA propone manejar la difusión de contenido dañino al requerir que las plataformas evalúen los riesgos asociados con la difusión de contenido dañino o ilegal y tomen medidas apropiadas para mitigar estos riesgos. Las plataformas deben implementar salvaguardas para asegurar que sus algoritmos no promuevan contenido dañino, y deben proporcionar a los usuarios herramientas para controlar el contenido al que están expuestos. La DSA también alienta a las plataformas a cooperar con denunciantes de confianza y verificadores de hechos para identificar y abordar más eficazmente el contenido dañino. En casos donde las plataformas no mitiguen adecuadamente los riesgos, pueden estar sujetas a acciones regulatorias, incluidas multas y otras sanciones.\"\n\n},\n\n# Question 5 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Qué protecciones específicas ofrece el RGPD a los niños con respecto a sus datos personales?\",\n\n    'answer': \"Los niños merecen una protección específica con respecto a sus datos personales, ya que pueden ser menos conscientes de los riesgos, las consecuencias, las salvaguardias y los derechos en relación con el tratamiento de datos personales. Esta protección específica debe aplicarse, en particular, al uso de datos personales de niños con fines de marketing o para crear perfiles de personalidad o de usuario, así como a la recopilación de datos personales con respecto a los niños cuando utilizan servicios ofrecidos directamente a un niño. El consentimiento del titular de la responsabilidad parental no debe ser necesario en el contexto de servicios preventivos o de asesoramiento ofrecidos directamente a un niño.\"\n\n},\n\n# Question 5 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Qué medidas sugiere la Ley de IA para proteger los derechos fundamentales en el despliegue de tecnologías de IA?\",\n\n    'answer': \"La Ley de IA incorpora varias medidas para proteger los derechos fundamentales, como exigir que los sistemas de IA se diseñen y utilicen de manera coherente con el respeto a la dignidad humana, la privacidad, la no discriminación y otros derechos fundamentales. Esto incluye incorporar mecanismos de supervisión humana, asegurarse de que los sistemas de IA no conduzcan a resultados sesgados o discriminatorios y proporcionar vías para que las personas impugnen las decisiones tomadas por sistemas de IA que los afecten significativamente. La Ley también promueve el desarrollo de códigos de conducta y medidas voluntarias por parte de los proveedores para asegurar que la IA se use de manera ética y en alineación con los valores sociales.\"\n\n},\n\n# Question 5 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Qué mecanismos de aplicación están incluidos en la DMA para garantizar el cumplimiento por parte de los guardianes?\",\n\n    'answer': \"La DMA incluye mecanismos de aplicación robustos, como la capacidad de la Comisión Europea para imponer multas de hasta el 10% del volumen de negocios total mundial anual del guardián por incumplimiento. En casos de infracciones repetidas, la Comisión puede imponer sanciones adicionales, incluidos remedios estructurales, como la desinversión de negocios. La DMA también permite pagos de multas periódicas para asegurar que los guardianes cumplan con las obligaciones y prohibiciones establecidas en la regulación.\"\n\n},\n\n# Question 5 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Qué medidas incluye la DSA para proteger la libertad de expresión mientras combate el contenido ilegal?\",\n\n    'answer': \"La DSA incluye medidas para proteger la libertad de expresión al asegurar que cualquier restricción sobre el contenido sea necesaria, proporcionada y legalmente justificada. Las plataformas deben proporcionar a los usuarios explicaciones claras cuando el contenido sea eliminado o el acceso sea restringido, y los usuarios deben tener el derecho de apelar tales decisiones. La DSA también requiere que las plataformas aseguren que los procesos de moderación de contenido sean justos y transparentes, con salvaguardias en su lugar para prevenir la eliminación arbitraria de contenido. Además, la DSA alienta a las plataformas a desarrollar códigos de conducta en colaboración con las partes interesadas para equilibrar la necesidad de combatir el contenido ilegal con la protección de la libertad de expresión.\"\n\n},\n\n# Question 6 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cómo define el RGPD los datos personales y cuáles son algunos ejemplos?\",\n\n    'answer': \"Los datos personales según el RGPD se definen como cualquier información relacionada con una persona física identificada o identificable (‘sujeto de datos’). Ejemplos incluyen el nombre de una persona, número de identificación, datos de localización, un identificador en línea o uno o más factores específicos de la identidad física, fisiológica, genética, mental, económica, cultural o social de esa persona física. La definición es amplia, abarcando diversas formas de datos que podrían usarse para identificar directa o indirectamente a un individuo.\"\n\n},\n\n# Question 6 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Qué categorías de sistemas de IA se consideran de alto riesgo según la Ley de IA?\",\n\n    'answer': \"Los sistemas de IA de alto riesgo según la Ley de IA incluyen aquellos utilizados en infraestructura crítica (como transporte, energía y suministro de agua), educación y formación profesional, empleo y gestión de trabajadores, acceso a servicios privados y públicos esenciales (como la calificación crediticia y los beneficios sociales), aplicación de la ley (como la vigilancia predictiva), gestión de migración, asilo y control de fronteras, y administración de justicia y procesos democráticos. Estos sistemas están sujetos a requisitos estrictos debido a los riesgos significativos que representan para los derechos fundamentales y la seguridad.\"\n\n},\n\n# Question 6 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo aborda la DMA la cuestión de la autopreferencia por parte de los guardianes?\",\n\n    'answer': \"La DMA prohíbe específicamente a los guardianes participar en prácticas de autopreferencia, donde favorecen sus propios productos o servicios sobre los de los competidores en sus plataformas. Esto incluye prácticas como clasificar sus propios productos más alto en los resultados de búsqueda o dar acceso preferente a datos. El objetivo es asegurar un campo de juego nivelado en los mercados digitales, donde la competencia se base en el mérito en lugar del poder de mercado del guardián. La prohibición de la autopreferencia es una de las obligaciones clave impuestas a los guardianes para prevenir el comportamiento anticompetitivo.\"\n\n},\n\n# Question 6 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cómo aborda la DSA la cuestión de la moderación de contenido en las plataformas en línea?\",\n\n    'answer': \"La DSA requiere que las plataformas en línea implementen políticas de moderación de contenido que sean transparentes, consistentes y alineadas con los derechos fundamentales. Las plataformas deben establecer términos y condiciones claros para la moderación de contenido y proporcionar a los usuarios información detallada sobre cómo se evalúa, elimina o restringe el contenido. La DSA también obliga a las plataformas a implementar mecanismos para que los usuarios apelen las decisiones de moderación de contenido, asegurando que los usuarios tengan la oportunidad de impugnar eliminaciones o restricciones injustificadas. Estas medidas están destinadas a crear un sistema de moderación de contenido justo y responsable que respete la libertad de expresión mientras combate el contenido ilegal.\"\n\n},\n\n# Question 7 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cuál es la base legal para el tratamiento de datos personales bajo el RGPD?\",\n\n    'answer': \"El RGPD establece varias bases legales para el tratamiento de datos personales, incluyendo: el consentimiento del interesado para el tratamiento; el tratamiento es necesario para la ejecución de un contrato en el que el interesado es parte; el tratamiento es necesario para el cumplimiento de una obligación legal; el tratamiento es necesario para proteger los intereses vitales del interesado o de otra persona física; el tratamiento es necesario para el desempeño de una tarea realizada en interés público o en el ejercicio de la autoridad oficial; y el tratamiento es necesario para los intereses legítimos perseguidos por el responsable del tratamiento o un tercero, salvo que dichos intereses queden anulados por los intereses o derechos y libertades fundamentales del interesado.\"\n\n},\n\n# Question 7 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cómo define la Ley de IA 'sistema de IA' y qué tecnologías entran bajo esta definición?\",\n\n    'answer': \"La Ley de IA define un 'sistema de IA' como software que se desarrolla con una o más de las técnicas y enfoques enumerados en la Ley, como el aprendizaje automático, los enfoques basados en la lógica y el conocimiento, y los enfoques estadísticos. Estos sistemas pueden, para un conjunto dado de objetivos definidos por humanos, generar resultados como contenido, predicciones, recomendaciones o decisiones que influyen en los entornos con los que interactúan. La definición es amplia e incluye una variedad de tecnologías de IA, desde algoritmos simples hasta modelos complejos de aprendizaje automático.\"\n\n},\n\n# Question 7 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cuáles son los criterios para identificar servicios de plataforma central bajo la DMA?\",\n\n    'answer': \"Los servicios de plataforma central bajo la DMA incluyen una gama de servicios digitales que sirven como puertas de entrada importantes para que los usuarios comerciales lleguen a los usuarios finales. Estos servicios incluyen servicios de intermediación en línea, como tiendas de aplicaciones y mercados, motores de búsqueda en línea, servicios de redes sociales, servicios de plataformas de intercambio de videos, servicios de comunicación interpersonal independientes del número, sistemas operativos, servicios de computación en la nube y servicios de publicidad. Un servicio se considera un servicio de plataforma central si tiene un impacto significativo en el mercado interno y es una puerta de entrada esencial para que los usuarios comerciales accedan a los usuarios finales.\"\n\n},\n\n# Question 7 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Qué obligaciones tienen las plataformas en línea muy grandes (VLOPs) bajo la DSA?\",\n\n    'answer': \"Las plataformas en línea muy grandes (VLOPs), definidas como plataformas con más de 45 millones de usuarios en la UE, tienen obligaciones adicionales bajo la DSA debido a su impacto significativo en la sociedad y el discurso público. Las VLOPs deben realizar evaluaciones de riesgos anuales para identificar y mitigar riesgos sistémicos, como la difusión de contenido ilegal, desinformación y contenido dañino. También están obligadas a proporcionar una mayor transparencia en sus algoritmos de recomendación de contenido, ofrecer a los usuarios más control sobre el contenido que ven y cooperar con las autoridades para prevenir y abordar los riesgos sistémicos. Estas obligaciones están destinadas a asegurar que las VLOPs operen de manera segura, transparente y respetuosa con los derechos fundamentales.\"\n\n},\n\n# Question 8 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cuáles son los derechos de los interesados bajo el RGPD?\",\n\n    'answer': \"El RGPD otorga a los interesados varios derechos, incluidos el derecho a ser informado, el derecho de acceso, el derecho de rectificación, el derecho de supresión (‘derecho al olvido’), el derecho a la limitación del tratamiento, el derecho a la portabilidad de los datos, el derecho a oponerse al tratamiento y derechos relacionados con la toma de decisiones automatizada y la elaboración de perfiles. Estos derechos permiten a las personas tener control sobre sus datos personales y garantizan la transparencia y responsabilidad en el tratamiento de datos.\"\n\n},\n\n# Question 8 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Qué obligaciones tienen los usuarios de sistemas de IA de alto riesgo bajo la Ley de IA?\",\n\n    'answer': \"Los usuarios de sistemas de IA de alto riesgo están obligados a operar los sistemas de acuerdo con las instrucciones proporcionadas por el proveedor del sistema de IA, monitorear el funcionamiento del sistema de IA e informar de inmediato cualquier incidente grave o fallo al proveedor y a las autoridades competentes. Los usuarios también deben mantener los registros generados por el sistema de IA, garantizar que se mantenga la supervisión humana y asegurarse de que el sistema de IA se utilice solo para su propósito previsto. Además, los usuarios son responsables de implementar medidas para mitigar los riesgos para los derechos fundamentales y la seguridad.\"\n\n},\n\n# Question 8 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo promueve la DMA la interoperabilidad entre servicios digitales?\",\n\n    'answer': \"La DMA promueve la interoperabilidad al exigir a los guardianes que aseguren que sus servicios de plataforma central puedan interactuar con servicios de terceros. Esto incluye poner a disposición las interfaces técnicas y la documentación necesarias para permitir la interoperabilidad. El objetivo es evitar que los guardianes bloqueen a los usuarios y usuarios comerciales en sus plataformas y permitir la competencia al permitir que nuevos entrantes y competidores más pequeños ofrezcan servicios complementarios o competitivos. La interoperabilidad se considera una medida clave para promover la innovación y la elección del consumidor en los mercados digitales.\"\n\n},\n\n# Question 8 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cómo mejora la DSA la protección de los menores en línea?\",\n\n    'answer': \"La DSA incluye disposiciones específicas para mejorar la protección de los menores en línea, reconociendo que los niños son particularmente vulnerables al contenido y prácticas dañinas. Las plataformas deben implementar medidas para asegurar que sus servicios sean seguros para los menores, incluyendo la moderación de contenido adecuada para la edad, controles parentales y restricciones sobre la publicidad dirigida a menores. La DSA también requiere que las plataformas proporcionen información clara y accesible a los menores y a sus padres sobre los riesgos asociados con las actividades en línea y cómo protegerse. Estas medidas están diseñadas para crear un entorno en línea más seguro para los niños y para empoderarlos a ellos y a sus tutores para que tomen decisiones informadas.\"\n\n},\n\n# Question 9 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cómo aborda el RGPD la protección de datos por diseño y por defecto?\",\n\n    'answer': \"El RGPD requiere que los responsables del tratamiento implementen la protección de datos por diseño y por defecto. Esto significa que las medidas de protección de datos deben integrarse en las actividades de tratamiento desde el principio y que solo se procesan los datos personales necesarios para cada propósito específico del tratamiento. El responsable del tratamiento debe adoptar medidas técnicas y organizativas adecuadas, como la seudonimización, para garantizar que, por defecto, los datos personales no se hagan accesibles a un número indefinido de personas sin el consentimiento del individuo.\"\n\n},\n\n# Question 9 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cómo aborda la Ley de IA el uso de sistemas de identificación biométrica?\",\n\n    'answer': \"La Ley de IA impone regulaciones estrictas sobre el uso de sistemas de identificación biométrica, especialmente aquellos utilizados en espacios públicos con fines de aplicación de la ley. El uso de sistemas de identificación biométrica remota en tiempo real en espacios accesibles al público está generalmente prohibido, con excepciones bajo condiciones específicas, como prevenir un ataque terrorista, localizar a un niño desaparecido o identificar a un sospechoso de un delito grave. Incluso en estos casos, el uso debe ser autorizado por autoridades judiciales u otras autoridades independientes y sujeto a estrictas salvaguardias para proteger los derechos fundamentales.\"\n\n},\n\n# Question 9 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Qué obligaciones impone la DMA a los guardianes en relación con el acceso y la portabilidad de datos?\",\n\n    'answer': \"La DMA impone obligaciones a los guardianes para proporcionar a los usuarios comerciales y a los usuarios finales acceso a los datos generados a través de sus interacciones en la plataforma. Esto incluye proporcionar datos en un formato estructurado, de uso común y legible por máquina para facilitar la portabilidad de datos. Los guardianes también están obligados a permitir que los usuarios comerciales accedan a datos que son necesarios para el desarrollo y mejora de sus propios productos y servicios. Estas obligaciones están destinadas a evitar que los guardianes utilicen su control sobre los datos para sofocar la competencia y la innovación.\"\n\n},\n\n# Question 9 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cuáles son las obligaciones de transparencia para las plataformas en línea en cuanto a sus algoritmos?\",\n\n    'answer': \"La DSA impone obligaciones de transparencia a las plataformas en línea para proporcionar información clara y accesible sobre cómo funcionan sus algoritmos, particularmente aquellos utilizados para la moderación, recomendación y clasificación de contenido. Las plataformas deben explicar los criterios y la lógica detrás de sus algoritmos, permitiendo a los usuarios entender cómo se toman las decisiones y cómo se les presenta el contenido. Las VLOPs tienen obligaciones adicionales para realizar auditorías algorítmicas y permitir que investigadores independientes evalúen el impacto de sus algoritmos en la sociedad. Estas medidas de transparencia están destinadas a aumentar la responsabilidad y la confianza en el ecosistema digital.\"\n\n},\n\n# Question 10 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cuál es el papel del Delegado de Protección de Datos (DPD) bajo el RGPD?\",\n\n    'answer': \"El Delegado de Protección de Datos (DPD) es responsable de supervisar las estrategias de protección de datos y garantizar el cumplimiento de los requisitos del RGPD. El DPD debe ser designado por autoridades y organismos públicos, y por organizaciones que realicen un seguimiento regular y sistemático de los interesados a gran escala o procesen categorías especiales de datos a gran escala. Las responsabilidades del DPD incluyen asesorar a la organización sobre las obligaciones del RGPD, monitorear el cumplimiento, proporcionar capacitación al personal, realizar auditorías y servir como punto de contacto para las autoridades de control y los interesados.\"\n\n},\n\n# Question 10 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cuáles son los requisitos para las evaluaciones de conformidad bajo la Ley de IA?\",\n\n    'answer': \"Los sistemas de IA de alto riesgo deben someterse a una evaluación de conformidad antes de que puedan ser comercializados o puestos en servicio. Esta evaluación implica evaluar si el sistema de IA cumple con los requisitos establecidos en la Ley de IA, incluidos la gestión de riesgos, la gobernanza de datos, la transparencia, la supervisión humana y la precisión. La evaluación puede ser realizada por el proveedor o por un organismo notificado, según la naturaleza del sistema de IA. La evaluación de conformidad debe estar documentada y el sistema de IA debe llevar el marcado CE que indique el cumplimiento de la regulación.\"\n\n},\n\n# Question 10 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo aborda la DMA la cuestión de las prácticas de vinculación y agrupación por parte de los guardianes?\",\n\n    'answer': \"La DMA prohíbe a los guardianes participar en prácticas de vinculación y agrupación que requieran a los usuarios comprar o usar servicios adicionales como condición para acceder al servicio de plataforma central del guardián. Por ejemplo, un guardián no puede requerir que los usuarios instalen o usen una aplicación o servicio específico como condición para usar su plataforma. La prohibición de la vinculación y la agrupación está destinada a evitar que los guardianes utilicen su poder de mercado para extender su dominio a otros mercados y garantizar que los usuarios tengan la libertad de elegir los servicios que desean utilizar.\"\n\n},\n\n# Question 10 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cómo aborda la DSA la cuestión de la desinformación y las noticias falsas en las plataformas digitales?\",\n\n    'answer': \"La DSA requiere que las plataformas, particularmente las VLOPs, tomen medidas proactivas para combatir la difusión de desinformación y noticias falsas. Esto incluye implementar mecanismos para detectar, evaluar y mitigar los riesgos asociados con la desinformación, colaborar con verificadores de hechos independientes y proporcionar a los usuarios información precisa y contexto. Las plataformas también deben asegurar que sus sistemas de moderación de contenido y recomendación no amplifiquen ni promuevan la desinformación. La DSA promueve la transparencia al requerir que las plataformas informen sobre sus esfuerzos para combatir la desinformación y proporcionen a los usuarios herramientas para identificar e informar sobre información falsa.\"\n\n},\n\n# Question 11 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cuáles son las implicaciones del RGPD para las actividades de tratamiento de datos transfronterizas?\",\n\n    'answer': \"El RGPD establece un marco para las actividades de tratamiento de datos transfronterizas para asegurar que la protección de datos sea consistente en toda la UE. Las organizaciones que procesan datos personales en varios estados miembros de la UE deben designar una autoridad de control principal, que actúe como punto único de contacto para supervisar el cumplimiento. El RGPD también facilita la cooperación entre las autoridades de control a través de mecanismos como el mecanismo de coherencia y el Comité Europeo de Protección de Datos (CEPD).\"\n\n},\n\n# Question 11 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Qué papel juegan las autoridades de supervisión nacionales bajo la Ley de IA?\",\n\n    'answer': \"Las autoridades de supervisión nacionales son responsables de supervisar la implementación y la aplicación de la Ley de IA dentro de sus respectivas jurisdicciones. Están encargadas de monitorear el cumplimiento de los sistemas de IA con los requisitos de la Ley, realizar inspecciones e investigaciones y tomar medidas de ejecución cuando sea necesario. Estas autoridades también desempeñan un papel clave en la coordinación con otras autoridades nacionales y la Comisión Europea para garantizar un enfoque armonizado de la regulación de la IA en toda la UE.\"\n\n},\n\n# Question 11 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cuáles son las consecuencias para los guardianes que no cumplan con la DMA?\",\n\n    'answer': \"Los guardianes que no cumplan con las obligaciones y prohibiciones establecidas en la DMA enfrentan consecuencias significativas, incluidas multas de hasta el 10% de su volumen de negocios total mundial anual. En casos de incumplimiento repetido, la Comisión Europea puede imponer medidas adicionales, como remedios estructurales, incluida la desinversión de partes del negocio. La DMA también prevé pagos de multas periódicas para asegurar que los guardianes cumplan con las obligaciones de manera continua. La aplicación de la DMA está diseñada para ser robusta para prevenir que los guardianes participen en comportamientos anticompetitivos.\"\n\n},\n\n# Question 11 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Qué papel juegan los denunciantes de confianza bajo la DSA?\",\n\n    'answer': \"La DSA reconoce el papel de los denunciantes de confianza, entidades con experiencia en la identificación de contenido ilegal, como socios importantes en la moderación de contenido. A los denunciantes de confianza se les concede prioridad en los mecanismos de notificación y acción, lo que significa que sus informes se procesan más rápidamente y con mayor precisión. Las plataformas deben asegurar que los informes de los denunciantes de confianza sean manejados por moderadores experimentados y que reciban retroalimentación sobre las acciones tomadas. La designación de denunciantes de confianza tiene como objetivo mejorar la eficiencia y efectividad de la moderación de contenido, particularmente en la lucha contra el contenido ilegal y actividades dañinas en línea.\"\n\n},\n\n# Question 12 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cómo maneja el RGPD las violaciones de datos y cuáles son las obligaciones de los responsables del tratamiento en tales casos?\",\n\n    'answer': \"Bajo el RGPD, los responsables del tratamiento deben notificar las violaciones de datos a la autoridad de control competente en un plazo de 72 horas desde que tengan conocimiento de la violación, a menos que sea improbable que la violación resulte en un riesgo para los derechos y libertades de las personas. Si la violación supone un alto riesgo para los individuos afectados, el responsable del tratamiento también debe informar a los interesados sin demora injustificada. El RGPD exige que las organizaciones implementen medidas técnicas y organizativas adecuadas para prevenir las violaciones de datos y mitigar su impacto.\"\n\n},\n\n# Question 12 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cómo fomenta la Ley de IA la innovación asegurando al mismo tiempo la seguridad y el cumplimiento?\",\n\n    'answer': \"La Ley de IA fomenta la innovación proporcionando entornos regulatorios de prueba (regulatory sandboxes), que son entornos controlados donde los desarrolladores de IA pueden probar sus sistemas bajo la supervisión de autoridades competentes sin enfrentar de inmediato todos los requisitos regulatorios. Estos entornos permiten la experimentación y el desarrollo de soluciones innovadoras de IA, mientras se asegura que se mantengan los estándares de seguridad, ética y legales. La Ley también promueve la adopción de códigos de conducta voluntarios para sistemas de IA que no son de alto riesgo, permitiendo que los proveedores demuestren su compromiso con prácticas éticas de IA.\"\n\n},\n\n# Question 12 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo mejora la DMA la protección del consumidor en los mercados digitales?\",\n\n    'answer': \"La DMA mejora la protección del consumidor al garantizar que los guardianes no participen en prácticas que perjudiquen a los consumidores, como la autopreferencia, los términos y condiciones injustos o la limitación del acceso a los datos. La DMA también promueve la transparencia en cómo operan los guardianes, exigiéndoles que proporcionen información clara y accesible a los consumidores sobre sus prácticas. Además, la DMA asegura que los consumidores tengan más opciones y control sobre los servicios digitales que utilizan, promoviendo la interoperabilidad y la portabilidad de datos. Al fomentar la competencia, la DMA busca mejorar la calidad y la asequibilidad de los servicios digitales para los consumidores.\"\n\n},\n\n# Question 12 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cómo promueve la DSA la responsabilidad de las plataformas en línea?\",\n\n    'answer': \"La DSA promueve la responsabilidad al imponer rigurosos requisitos de informe y transparencia a las plataformas en línea. Las plataformas deben publicar informes de transparencia regulares que detallen sus actividades de moderación de contenido, incluyendo el número de acciones de eliminación, las razones de las eliminaciones y los resultados de las apelaciones de los usuarios. Las VLOPs también están obligadas a someterse a auditorías independientes de sus prácticas de moderación de contenido y gestión de riesgos. Estas auditorías están destinadas a evaluar el cumplimiento de la plataforma con la DSA e identificar áreas de mejora. Al promover la transparencia y la responsabilidad, la DSA busca generar confianza en el entorno digital y asegurar que las plataformas actúen de manera responsable.\"\n\n},\n\n# Question 13 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cuáles son las restricciones para el tratamiento de categorías especiales de datos personales bajo el RGPD?\",\n\n    'answer': \"El RGPD impone reglas más estrictas para el tratamiento de categorías especiales de datos personales, como datos que revelen el origen racial o étnico, opiniones políticas, creencias religiosas o filosóficas, afiliación sindical, datos genéticos, datos biométricos, datos de salud y datos relativos a la vida sexual o la orientación sexual de una persona. El tratamiento de dichos datos está prohibido a menos que se cumplan condiciones específicas, como obtener el consentimiento explícito del interesado, cumplir con obligaciones legales en el ámbito del empleo y la seguridad social, o proteger los intereses vitales del interesado.\"\n\n},\n\n# Question 13 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cómo aborda la Ley de IA la transparencia de los sistemas de IA?\",\n\n    'answer': \"La Ley de IA exige que los sistemas de IA, especialmente los de alto riesgo, sean diseñados y desarrollados con transparencia en mente. Esto incluye proporcionar información clara y accesible a los usuarios sobre el propósito, las capacidades, las limitaciones y el funcionamiento del sistema de IA. Los usuarios deben ser informados cuando estén interactuando con un sistema de IA, especialmente en los casos en que la IA se utiliza para tomar decisiones con impactos significativos en las personas. Los requisitos de transparencia están dirigidos a asegurar que los usuarios y las personas afectadas entiendan cómo y por qué los sistemas de IA toman decisiones.\"\n\n},\n\n# Question 13 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo aborda la DMA la cuestión del acceso a los datos de los usuarios comerciales por parte de los guardianes?\",\n\n    'answer': \"La DMA impone obligaciones a los guardianes para proporcionar a los usuarios comerciales acceso a los datos que generan a través de sus interacciones en la plataforma. Esto incluye el acceso a datos agregados y anonimizados, así como a datos que son esenciales para el desarrollo y la mejora de los productos y servicios del usuario comercial. La DMA también prohíbe a los guardianes usar datos no públicos de los usuarios comerciales para competir contra ellos, asegurando que los guardianes no exploten su acceso a los datos para obtener una ventaja competitiva injusta.\"\n\n},\n\n# Question 13 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cuáles son las sanciones por incumplimiento de la DSA?\",\n\n    'answer': \"La DSA prevé sanciones sustanciales por incumplimiento, incluidas multas de hasta el 6% del volumen de negocios total anual mundial de la plataforma. En casos de incumplimiento repetido o grave, la DSA permite medidas adicionales, como la suspensión temporal de los servicios de la plataforma u otras acciones correctivas. La aplicación de la DSA está supervisada por autoridades reguladoras nacionales, que tienen el poder de investigar y sancionar a las plataformas que violen la regulación. Estas sanciones están diseñadas para asegurar que las plataformas tomen en serio sus obligaciones y que las disposiciones de la DSA se implementen efectivamente.\"\n\n},\n\n# Question 14 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cómo regula el RGPD la toma de decisiones automatizadas y la elaboración de perfiles?\",\n\n    'answer': \"El RGPD impone restricciones a la toma de decisiones automatizada, incluida la elaboración de perfiles, cuando las decisiones se toman únicamente en base al tratamiento automatizado y afectan significativamente a las personas. Dicho tratamiento solo se permite en situaciones específicas, como cuando es necesario para la ejecución de un contrato, autorizado por la ley de la Unión o del Estado miembro, o basado en el consentimiento explícito del interesado. Las organizaciones deben asegurarse de que las personas sean informadas sobre la existencia de decisiones automatizadas, la lógica involucrada y las posibles consecuencias. Los interesados tienen derecho a impugnar las decisiones automatizadas y solicitar intervención humana.\"\n\n},\n\n# Question 14 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cuáles son las obligaciones relacionadas con la calidad de los datos bajo la Ley de IA?\",\n\n    'answer': \"La Ley de IA requiere que los sistemas de IA de alto riesgo sean entrenados, probados y validados utilizando conjuntos de datos de alta calidad que sean relevantes, representativos, libres de errores y completos. Los datos deben ser seleccionados cuidadosamente para evitar sesgos que podrían llevar a resultados discriminatorios. Los proveedores deben asegurarse de que el marco de gobernanza de datos incluya medidas para evaluar y mitigar los riesgos relacionados con la calidad de los datos, como el uso de conjuntos de datos diversos y representativos, validar la precisión y fiabilidad de los datos, y actualizar regularmente los conjuntos de datos para reflejar los cambios a lo largo del tiempo.\"\n\n},\n\n# Question 14 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo asegura la DMA el acceso justo y no discriminatorio a los servicios de plataforma central?\",\n\n    'answer': \"La DMA requiere que los guardianes aseguren que sus servicios de plataforma central se ofrezcan en términos justos, razonables y no discriminatorios. Esto significa que los guardianes no pueden imponer términos o condiciones injustas a los usuarios comerciales ni participar en prácticas que favorezcan sus propios servicios sobre los de los competidores. La DMA también requiere que los guardianes proporcionen transparencia en cómo operan, incluida información clara y accesible sobre los términos y condiciones para usar sus servicios. Estas medidas están destinadas a prevenir que los guardianes abusen de su poder de mercado y asegurar un campo de juego nivelado en los mercados digitales.\"\n\n},\n\n# Question 14 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cómo aborda la DSA la cuestión de los bienes, servicios y contenidos ilegales en línea?\",\n\n    'answer': \"La DSA requiere que las plataformas implementen medidas para detectar y eliminar bienes, servicios y contenidos ilegales de sus servicios. Esto incluye asegurar que los vendedores y proveedores de servicios en sus plataformas estén debidamente identificados y que cumplan con las leyes y regulaciones aplicables. Las plataformas también deben proporcionar a los usuarios mecanismos claros para informar sobre bienes y servicios ilegales, y deben actuar rápidamente para eliminar o deshabilitar el acceso a dicho contenido. Las disposiciones de la DSA están diseñadas para proteger a los consumidores y asegurar que los mercados en línea operen de manera segura y legal.\"\n\n},\n\n# Question 15 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Qué sanciones y medidas de ejecución se prevén en el RGPD?\",\n\n    'answer': \"El RGPD prevé sanciones sustanciales y medidas de ejecución para garantizar el cumplimiento. Las autoridades de control tienen el poder de imponer multas administrativas de hasta 20 millones de euros o el 4% del volumen de negocios anual total mundial del ejercicio financiero anterior, lo que sea mayor, por las violaciones más graves. Las sanciones se determinan en función de factores como la naturaleza, gravedad y duración de la infracción, el carácter intencional o negligente de la infracción, y las medidas adoptadas por la organización para mitigar el daño.\"\n\n},\n\n# Question 15 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cómo regula la Ley de IA el uso de la IA en la aplicación de la ley y la seguridad pública?\",\n\n    'answer': \"La Ley de IA impone estrictas regulaciones sobre el uso de sistemas de IA en la aplicación de la ley y la seguridad pública, especialmente aquellos utilizados para la vigilancia predictiva, la identificación biométrica y la vigilancia. Estos sistemas se consideran de alto riesgo y están sujetos a un riguroso escrutinio para asegurar que no infrinjan los derechos fundamentales, como la privacidad y la no discriminación. Las agencias de aplicación de la ley deben realizar una evaluación de riesgos detallada e implementar salvaguardias para garantizar que el uso de sistemas de IA sea necesario, proporcionado y respetuoso de los derechos humanos.\"\n\n},\n\n# Question 15 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo promueve la DMA la innovación y la competencia en los mercados digitales?\",\n\n    'answer': \"La DMA promueve la innovación y la competencia al prevenir que los guardianes participen en prácticas que sofocan la competencia, como la autopreferencia, la vinculación y la agrupación. Al asegurar que los guardianes operen en términos justos, razonables y no discriminatorios, la DMA crea oportunidades para que nuevos entrantes y competidores más pequeños compitan en igualdad de condiciones. La DMA también promueve la interoperabilidad y la portabilidad de datos, permitiendo a las empresas desarrollar servicios innovadores que puedan interactuar con la plataforma del guardián. Estas medidas están diseñadas para fomentar un mercado digital dinámico y competitivo que beneficie a los consumidores y a las empresas por igual.\"\n\n},\n\n# Question 15 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cómo apoya la DSA los derechos de los consumidores en el mercado digital?\",\n\n    'answer': \"La DSA fortalece los derechos de los consumidores al asegurar que las plataformas en línea proporcionen información clara y accesible sobre los bienes, servicios y contenidos disponibles en sus plataformas. Esto incluye requerir que las plataformas divulguen información sobre la identidad de los vendedores, los términos y condiciones de las transacciones, y la naturaleza de los bienes y servicios ofrecidos. Los consumidores también deben ser informados sobre sus derechos, incluyendo el derecho a retirarse de una transacción, el derecho a un reembolso y el derecho a acceder a mecanismos efectivos de resolución de disputas. Las disposiciones de protección al consumidor de la DSA están diseñadas para crear un mercado digital seguro y transparente.\"\n\n},\n\n# Question 16 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cuál es el papel del Comité Europeo de Protección de Datos (CEPD) bajo el RGPD?\",\n\n    'answer': \"El Comité Europeo de Protección de Datos (CEPD) es un organismo independiente establecido por el RGPD para garantizar la aplicación coherente de las normas de protección de datos en toda la UE. El CEPD está compuesto por representantes de las autoridades nacionales de protección de datos y del Supervisor Europeo de Protección de Datos (SEPD). Sus responsabilidades incluyen emitir directrices, recomendaciones y buenas prácticas sobre la interpretación y aplicación del RGPD, resolver disputas entre autoridades de control y asesorar a la Comisión Europea sobre cuestiones de protección de datos.\"\n\n},\n\n# Question 16 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cómo aborda la Ley de IA el problema del sesgo y la discriminación en los sistemas de IA?\",\n\n    'answer': \"La Ley de IA exige que los sistemas de IA, especialmente los de alto riesgo, sean diseñados y desarrollados de manera que prevenga, identifique y mitigue los sesgos que podrían llevar a resultados discriminatorios. Los proveedores deben tomar medidas para asegurar que los sistemas de IA no produzcan resultados que desventajen injustamente a individuos o grupos basados en características protegidas como la raza, el género o la religión. Esto incluye el uso de conjuntos de datos diversos, la realización de auditorías de sesgo y la implementación de medidas correctivas para abordar los sesgos identificados. La Ley también enfatiza la importancia de la supervisión humana en la prevención y el abordaje del sesgo.\"\n\n},\n\n# Question 16 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo aborda la DMA la cuestión de las fusiones y adquisiciones por parte de los guardianes?\",\n\n    'answer': \"La DMA requiere que los guardianes informen a la Comisión Europea sobre cualquier fusión, adquisición o concentración prevista que involucre a otros proveedores de servicios de plataforma central o servicios digitales. Este requisito de notificación permite a la Comisión evaluar si la transacción propuesta socavaría los objetivos de la DMA, como reforzar el poder de mercado del guardián o reducir la competencia en los mercados digitales. Las disposiciones de la DMA sobre fusiones y adquisiciones están destinadas a prevenir que los guardianes consoliden su dominio a través de adquisiciones estratégicas y a asegurar que la competencia siga siendo robusta en los mercados digitales.\"\n\n},\n\n# Question 16 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cómo maneja la DSA la cuestión del acoso y abuso en línea?\",\n\n    'answer': \"La DSA requiere que las plataformas implementen medidas para combatir el acoso y abuso en línea, incluyendo proporcionar a los usuarios herramientas para informar y bloquear contenido y comportamientos abusivos. Las plataformas deben actuar rápidamente para eliminar o deshabilitar el acceso al contenido que constituye acoso o abuso, y deben proporcionar apoyo a las víctimas. La DSA también alienta a las plataformas a colaborar con las autoridades y organizaciones de la sociedad civil para abordar el acoso en línea y desarrollar mejores prácticas para crear un entorno en línea seguro. Estas medidas están destinadas a proteger a los usuarios del daño y promover un espacio digital respetuoso e inclusivo.\"\n\n},\n\n# Question 17 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cómo aborda el RGPD el tema del consentimiento en el tratamiento de datos?\",\n\n    'answer': \"Según el RGPD, el consentimiento debe ser libre, específico, informado e inequívoco. Las organizaciones deben asegurarse de que el consentimiento se obtenga mediante una acción afirmativa clara, como marcar una casilla en un sitio web, y que sea distinguible de otros asuntos. Se debe informar al interesado de su derecho a retirar el consentimiento en cualquier momento, y la retirada debe ser tan fácil como otorgar el consentimiento. Además, para los niños menores de 16 años, se requiere el consentimiento parental para el tratamiento de sus datos.\"\n\n},\n\n# Question 17 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cuál es el papel del Comité Europeo de Inteligencia Artificial (EAIB) bajo la Ley de IA?\",\n\n    'answer': \"El Comité Europeo de Inteligencia Artificial (EAIB) se establece bajo la Ley de IA para facilitar la cooperación y coordinación entre las autoridades de supervisión nacionales y la Comisión Europea. El EAIB es responsable de emitir directrices, recomendaciones y mejores prácticas sobre la implementación de la Ley de IA, proporcionar asesoramiento a la Comisión Europea sobre cuestiones relacionadas con la IA y promover la aplicación armonizada de la Ley en toda la UE. El EAIB también juega un papel en la resolución de disputas entre autoridades nacionales y en asegurar la consistencia en la interpretación y aplicación de la Ley de IA.\"\n\n},\n\n# Question 17 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo aborda la DMA la cuestión de los patrones oscuros y las prácticas de diseño engañoso por parte de los guardianes?\",\n\n    'answer': \"La DMA prohíbe a los guardianes usar patrones oscuros y prácticas de diseño engañoso que manipulen o engañen a los usuarios para que tomen decisiones que no son en su mejor interés. Esto incluye prácticas como ocultar información importante, dificultar que los usuarios ejerzan sus derechos o empujar a los usuarios hacia ciertas elecciones. La DMA requiere que los guardianes proporcionen información clara y accesible a los usuarios y que diseñen sus interfaces de manera que respeten la autonomía y la elección del usuario. Estas disposiciones están destinadas a proteger a los consumidores de prácticas manipulativas y asegurar que los servicios digitales sean transparentes y fáciles de usar.\"\n\n},\n\n# Question 17 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cómo asegura la DSA que los usuarios tengan control sobre sus datos y privacidad?\",\n\n    'answer': \"La DSA mejora el control de los usuarios sobre los datos y la privacidad al requerir que las plataformas proporcionen información clara y accesible sobre cómo se recopilan, procesan y utilizan los datos de los usuarios. Los usuarios deben ser informados sobre sus derechos para acceder, rectificar y eliminar sus datos, así como su derecho a oponerse al procesamiento de datos. La DSA también requiere que las plataformas implementen principios de privacidad por diseño y por defecto, asegurando que la privacidad de los usuarios esté protegida desde el principio. Además, las plataformas deben proporcionar a los usuarios herramientas para gestionar sus configuraciones de privacidad y controlar el uso de sus datos para publicidad dirigida.\"\n\n},\n\n# Question 18 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cuál es el enfoque del RGPD para las transferencias internacionales de datos?\",\n\n    'answer': \"El RGPD permite las transferencias internacionales de datos solo si el tercer país, territorio u organización internacional asegura un nivel adecuado de protección de datos, según lo determine la Comisión Europea. En ausencia de una decisión de adecuación, las transferencias están permitidas bajo garantías adecuadas, como normas corporativas vinculantes o cláusulas contractuales tipo. En circunstancias específicas, las derogaciones para situaciones específicas, como el consentimiento explícito del interesado, pueden permitir las transferencias. El RGPD busca asegurar que los datos personales transferidos fuera de la UE reciban el mismo nivel de protección que dentro de la UE.\"\n\n},\n\n# Question 18 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cómo impacta la Ley de IA el uso de la IA en la salud?\",\n\n    'answer': \"La Ley de IA reconoce los beneficios potenciales de la IA en la salud, como mejorar el diagnóstico, el tratamiento y los resultados de los pacientes. Sin embargo, también reconoce los riesgos asociados con el uso de la IA en este sector sensible. Los sistemas de IA utilizados en salud, particularmente aquellos que involucran la toma de decisiones o proporcionan recomendaciones a profesionales de la salud, se clasifican como de alto riesgo y están sujetos a requisitos estrictos. Estos incluyen garantizar la precisión y la fiabilidad de los sistemas de IA, mantener la supervisión humana y proteger los datos de los pacientes. La Ley también enfatiza la importancia de la transparencia y el consentimiento informado en el uso de la IA en salud.\"\n\n},\n\n# Question 18 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo promueve la DMA la transparencia en la publicidad digital?\",\n\n    'answer': \"La DMA promueve la transparencia en la publicidad digital al requerir que los guardianes proporcionen a los anunciantes y editores acceso a los datos relacionados con sus campañas publicitarias, incluyendo información sobre precios, rendimiento y criterios de segmentación. Los guardianes también deben asegurar que sus servicios de publicidad se ofrezcan en términos justos, razonables y no discriminatorios, y tienen prohibido usar datos no públicos para obtener una ventaja injusta en el mercado publicitario. Estas disposiciones están destinadas a promover la competencia y la transparencia en la publicidad digital, asegurando que los anunciantes y editores tengan la información que necesitan para tomar decisiones informadas.\"\n\n},\n\n# Question 18 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cómo aborda la DSA la cuestión de la transparencia y la responsabilidad algorítmica?\",\n\n    'answer': \"La DSA requiere que las plataformas, particularmente las VLOPs, proporcionen transparencia sobre cómo funcionan sus algoritmos, incluyendo los criterios utilizados para la recomendación, clasificación y eliminación de contenido. Las plataformas deben explicar la lógica detrás de sus algoritmos y proporcionar a los usuarios opciones para controlar cómo los algoritmos afectan su experiencia en línea. La DSA también obliga a las plataformas a realizar auditorías regulares de sus algoritmos para evaluar su impacto en los usuarios y la sociedad. Estas auditorías deben ser realizadas por terceros independientes y deben evaluar si los algoritmos son justos, no discriminatorios y alineados con los derechos fundamentales.\"\n\n},\n\n# Question 19 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Cómo impacta el RGPD a las pequeñas y medianas empresas (PYMEs)?\",\n\n    'answer': \"El RGPD reconoce los desafíos a los que se enfrentan las pequeñas y medianas empresas (PYMEs) y proporciona ciertas exenciones y derogaciones para aliviar su carga de cumplimiento. Por ejemplo, las PYMEs con menos de 250 empleados no están obligadas a mantener registros de las actividades de tratamiento a menos que el tratamiento sea regular, suponga un riesgo para los derechos y libertades de los interesados, o implique categorías especiales de datos. Sin embargo, las PYMEs deben seguir cumpliendo con otros requisitos del RGPD, como la notificación de violaciones de datos, los derechos de los interesados y la designación de un DPD si es necesario.\"\n\n},\n\n# Question 19 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Cómo aborda la Ley de IA el tema de la alfabetización en IA y la conciencia pública?\",\n\n    'answer': \"La Ley de IA fomenta iniciativas para promover la alfabetización en IA y la conciencia pública, reconociendo que los ciudadanos informados y educados son esenciales para la adopción responsable de las tecnologías de IA. La Ley solicita el desarrollo de programas educativos y recursos para ayudar a las personas a comprender las capacidades, limitaciones y riesgos asociados con la IA. También promueve consultas públicas y la participación de partes interesadas para asegurar que las perspectivas de varios grupos, incluidas las de la sociedad civil, se consideren en el desarrollo y despliegue de sistemas de IA.\"\n\n},\n\n# Question 19 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Cómo aborda la DMA la cuestión del acceso a los servicios de plataforma central por parte de los usuarios finales?\",\n\n    'answer': \"La DMA asegura que los usuarios finales tengan acceso a los servicios de plataforma central en términos justos y no discriminatorios. Los guardianes tienen prohibido restringir o degradar la calidad del acceso a sus servicios o participar en prácticas que limiten la elección del usuario, como obligar a los usuarios a instalar ciertas aplicaciones o usar servicios específicos. La DMA también promueve la portabilidad de datos, permitiendo a los usuarios finales transferir sus datos a otros servicios y aprovechar ofertas competitivas. Estas disposiciones están diseñadas para mejorar la elección y el control del usuario sobre los servicios digitales que utilizan.\"\n\n},\n\n# Question 19 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cuáles son los requisitos para que las plataformas en línea cooperen con las autoridades reguladoras bajo la DSA?\",\n\n    'answer': \"La DSA requiere que las plataformas en línea cooperen con las autoridades reguladoras proporcionando acceso a datos, registros e información necesarios para fines de monitoreo y cumplimiento. Las plataformas deben responder rápidamente a las solicitudes de las autoridades y facilitar inspecciones e investigaciones. La DSA también obliga a las plataformas a proporcionar informes de transparencia y someterse a auditorías independientes para demostrar el cumplimiento con la regulación. La cooperación con las autoridades es esencial para asegurar que las plataformas cumplan con sus obligaciones y que las disposiciones de la DSA se apliquen efectivamente.\"\n\n},\n\n# Question 20 from GDPR\n\n{\n\n    'law': 'gdpr',\n\n    'question': \"¿Qué medidas recomienda el RGPD para garantizar la seguridad de los datos?\",\n\n    'answer': \"El RGPD requiere que las organizaciones implementen medidas técnicas y organizativas adecuadas para garantizar un nivel de seguridad acorde con el riesgo. Esto incluye medidas como la seudonimización y el cifrado de datos personales, garantizar la confidencialidad, integridad, disponibilidad y resiliencia continuas de los sistemas y servicios de tratamiento, y probar, evaluar y evaluar regularmente la efectividad de las medidas de seguridad. El RGPD también enfatiza la necesidad de realizar evaluaciones de impacto de protección de datos (DPIA) cuando las operaciones de tratamiento probablemente resulten en un alto riesgo para los derechos y libertades de las personas físicas.\"\n\n},\n\n# Question 20 from AI Act\n\n{\n\n    'law': 'ai_act',\n\n    'question': \"¿Qué medidas incluye la Ley de IA para apoyar el desarrollo ético de la IA?\",\n\n    'answer': \"La Ley de IA apoya el desarrollo ético de la IA fomentando la adopción de códigos de conducta voluntarios, promoviendo la investigación sobre IA ética y promoviendo el desarrollo de sistemas de IA que se alineen con los valores europeos y los derechos fundamentales. La Ley enfatiza la importancia de la IA centrada en el ser humano, donde los sistemas de IA están diseñados para mejorar las capacidades y el bienestar humanos mientras respetan la dignidad y la autonomía humanas. También apoya la creación de entornos regulatorios de prueba (regulatory sandboxes) para permitir a los desarrolladores experimentar con soluciones innovadoras de IA en un entorno controlado, asegurando que las consideraciones éticas se integren en el diseño y despliegue de las tecnologías de IA.\"\n\n},\n\n# Question 20 from DMA\n\n{\n\n    'law': 'dma',\n\n    'question': \"¿Qué papel desempeña la Comisión Europea en la aplicación de la DMA?\",\n\n    'answer': \"La Comisión Europea es responsable de la aplicación de la DMA, incluida la supervisión del cumplimiento, la realización de investigaciones y la imposición de sanciones por incumplimiento. La Comisión tiene la autoridad para imponer multas, pagos de multas periódicas y remedios estructurales a los guardianes que violen las obligaciones y prohibiciones de la DMA. La Comisión también tiene el poder de iniciar investigaciones de mercado para evaluar si nuevos servicios deben ser designados como servicios de plataforma central o si deben imponerse obligaciones adicionales a los guardianes. La aplicación de la DMA está diseñada para ser robusta y efectiva, asegurando que los guardianes operen de manera que promuevan la competencia y la innovación en los mercados digitales.\"\n\n},\n\n# Question 20 from DSA\n\n{\n\n    'law': 'dsa',\n\n    'question': \"¿Cómo promueve la DSA el desarrollo de códigos de conducta para las plataformas en línea?\",\n\n    'answer': \"La DSA fomenta el desarrollo de códigos de conducta para las plataformas en línea para abordar cuestiones específicas como la moderación de contenido, la transparencia algorítmica y la protección de menores. Estos códigos de conducta se desarrollan en colaboración con las partes interesadas de la industria, organizaciones de la sociedad civil y autoridades reguladoras. La DSA promueve la adopción de estas medidas voluntarias para asegurar que las plataformas operen de manera responsable y ética. Los códigos de conducta proporcionan un marco para las mejores prácticas y ayudan a las plataformas a alinear sus operaciones con los objetivos de la DSA, mientras permiten flexibilidad e innovación.\"\n\n}\n\n]\n\nlaws_info = {\n    'gdpr': {\n        'file_path': '/kaggle/input/spanish-laws/spanish_gdpr.html',\n        'collection_name': 'chunk-embeddings-index',\n        'questions_answers': [qa for qa in integrated_questions_answers if qa['law'] == 'gdpr']\n    },\n    'ai_act': {\n        'file_path': '/kaggle/input/spanish-laws/spanish_AI_act.html',\n        'collection_name': 'chunk-embeddings-index',\n        'questions_answers': [qa for qa in integrated_questions_answers if qa['law'] == 'ai_act']\n    },\n    'dma': {\n        'file_path': '/kaggle/input/spanish-laws/spanish_dma.html',\n        'collection_name': 'DMA_Chunk',\n        'questions_answers': [qa for qa in integrated_questions_answers if qa['law'] == 'dma']\n    },\n    'dsa': {\n        'file_path': '/kaggle/input/spanish-laws/spanish_dsa.html',\n        'collection_name': 'DSA_Chunk',\n        'questions_answers': [qa for qa in integrated_questions_answers if qa['law'] == 'dsa']\n    },\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:50:25.984840Z","iopub.execute_input":"2024-12-05T16:50:25.985514Z","iopub.status.idle":"2024-12-05T16:50:26.034625Z","shell.execute_reply.started":"2024-12-05T16:50:25.985478Z","shell.execute_reply":"2024-12-05T16:50:26.033707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import defaultdict\nfrom transformers import pipeline\nfrom sentence_transformers import SentenceTransformer, util\nimport numpy as np\nimport torch\n\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nsummarizer = pipeline(\"summarization\", model=\"csebuetnlp/mT5_multilingual_XLSum\",device=0 if torch.cuda.is_available() else -1)\ncosine_model = SentenceTransformer('dccuchile/bert-base-spanish-wwm-uncased',device=device) \n\n\ndef embed_query(query, model_name):\n    return cosine_model.encode(query, convert_to_tensor=True)\n    \ndef summarize_text_huggingface_with_retry(text, max_length=350, min_length=100, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)\n            return summary[0]['summary_text']\n        except Exception as e:\n            print(f\"Attempt {attempt + 1} failed: {e}\")\n            if attempt < max_retries - 1:\n                time.sleep(2 ** attempt)\n            else:\n                print(\"Max retries reached. Returning None.\")\n                return None\n\ndef calculate_cosine_similarity(embedding1, embedding2):\n    return np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n    \nfor law, law_info in laws_info.items():\n    print(f\"\\nProcessing law: {law.upper()}\")\n    \n    for qa in law_info['questions_answers']:\n        question = qa['question']\n        reference_answer = qa['answer']\n        \n        print(f\"Querying for question: {question}\")\n\n        query_embedding = embed_query(question, model_name)\n\n        results = query_pinecone_db(query_embedding, index, namespace=law, top_k=1)\n\n        if results and 'matches' in results and results['matches']:\n            retrieved_chunk_id = results['matches'][0]['id']\n            \n            if law in chunks_dict:\n                retrieved_chunk_index = int(retrieved_chunk_id.split('_')[-1])\n                retrieved_chunk = chunks_dict[law][retrieved_chunk_index]\n\n                print(f\"Retrieved chunk {retrieved_chunk_index} from {law.upper()}:\")\n                print(retrieved_chunk)\n\n                summary = summarize_text_huggingface_with_retry(retrieved_chunk)\n                print(summary)\n                qa['summary'] = summary\n                if summary:\n                    answer_embedding = cosine_model.encode(reference_answer, convert_to_tensor=False)\n                    summary_embedding = cosine_model.encode(summary, convert_to_tensor=False)\n                    qa['answer_embedding'] = answer_embedding\n                    qa['summary_embedding'] = summary_embedding\n                    \n                    cosine_similarity = calculate_cosine_similarity(answer_embedding, summary_embedding)\n                    qa['cosine_similarity'] = cosine_similarity\n                    \n                    semantic_similarity = util.pytorch_cos_sim(\n                        semantic_model.encode(reference_answer, convert_to_tensor=True),\n                        semantic_model.encode(summary, convert_to_tensor=True)\n                    ).item()\n                    qa['semantic_similarity'] = semantic_similarity\n                    \n                    print(f\"Question: {question}\")\n                    print(f\"Summary: {summary}\")\n                    print(f\"Cosine Similarity: {cosine_similarity:.4f}\")\n                    print(f\"Semantic Similarity: {semantic_similarity:.4f}\")\n                else:\n                    print(f\"No summary generated for question: {question}\")\n\n            else:\n                print(f\"Error: '{law}' not found in chunks_dict.\")\n        else:\n            print(f\"No results found for {law.upper()} for the question: {question}\")\n\naverages = {}\nfor law, info in laws_info.items():\n    total_cosine = 0\n    total_semantic = 0\n    count = 0\n\n    for qa in info['questions_answers']:\n        if 'cosine_similarity' in qa and 'semantic_similarity' in qa:\n            total_cosine += qa['cosine_similarity']\n            total_semantic += qa['semantic_similarity']\n            count += 1\n    \n    if count > 0:\n        avg_cosine = total_cosine / count\n        avg_semantic = total_semantic / count\n        averages[law] = {\n            'average_cosine_similarity': avg_cosine,\n            'average_semantic_similarity': avg_semantic\n        }\n        print(f\"\\nAverage Cosine Similarity for {law.upper()}: {avg_cosine:.4f}\")\n        print(f\"Average Semantic Similarity for {law.upper()}: {avg_semantic:.4f}\")\n    else:\n        print(f\"\\nNo valid similarity scores for {law.upper()}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:50:29.216872Z","iopub.execute_input":"2024-12-05T16:50:29.217255Z","iopub.status.idle":"2024-12-05T16:55:20.687882Z","shell.execute_reply.started":"2024-12-05T16:50:29.217220Z","shell.execute_reply":"2024-12-05T16:55:20.687016Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\ndef measure_and_average_query_latency(laws_info, model, tokenizer, top_k=1):\n    latency_results = {law: [] for law in laws_info.keys()}  \n    all_latencies = []\n\n    for law, info in laws_info.items():\n        print(f\"\\nMeasuring query latency for {law.upper()} namespace:\")\n\n        if not info.get('questions_answers', []):\n            print(f\"No questions found for law: {law}\")\n            continue\n\n        for qa in info['questions_answers']:\n            query = qa.get('question', None)\n            if not query:\n                print(f\"Skipping missing query for law: {law}\")\n                continue\n\n            try:\n                query_embedding = get_embedding(query, model, tokenizer)\n                print(f\"Generated embedding for query: {query}\")\n            except Exception as e:\n                print(f\"Error generating embedding for query: {query}. Error: {e}\")\n                continue\n\n            start_time = time.time()\n\n            try:\n                results = index.query(\n                    vector=query_embedding.tolist(), \n                    top_k=top_k,\n                    namespace=law\n                )\n            except Exception as e:\n                print(f\"Error querying Pinecone for {query}: {e}\")\n                continue\n\n            end_time = time.time()\n\n            latency = end_time - start_time\n            latency_results[law].append(latency)\n            all_latencies.append(latency)\n\n            print(f\"Query: {query}\")\n            print(f\"Latency: {latency:.4f} seconds\")\n            print(\"----\\n\")\n    \n    for law in latency_results:\n        print(f\"Latencies for {law}: {latency_results[law]}\")\n        if latency_results[law]: \n            avg_latency = sum(latency_results[law]) / len(latency_results[law])\n            print(f\"{law.upper()} Average Query Latency: {avg_latency:.4f} seconds\")\n        else:\n            print(f\"{law.upper()} has no recorded latencies.\")\n\n    if all_latencies:\n        overall_avg_latency = sum(all_latencies) / len(all_latencies)\n        print(f\"\\nOverall Average Query Latency: {overall_avg_latency:.4f} seconds\")\n    else:\n        print(\"No latencies recorded across all laws.\")\n\ndef get_embedding(text, model, tokenizer, max_length=512):\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=True,\n        max_length=max_length\n    )\n    with torch.no_grad():\n        outputs = model(**inputs)\n    return outputs.last_hidden_state[:, 0, :].squeeze(0).cpu().numpy()\n\nfrom transformers import AutoTokenizer, AutoModel\n\nembedding_model = AutoModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\ntokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n\nmeasure_and_average_query_latency(laws_info, embedding_model, tokenizer, top_k=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:55:48.357842Z","iopub.execute_input":"2024-12-05T16:55:48.358443Z","iopub.status.idle":"2024-12-05T16:55:56.613198Z","shell.execute_reply.started":"2024-12-05T16:55:48.358406Z","shell.execute_reply":"2024-12-05T16:55:56.612210Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load the other 80 questions, to retrieve the most relevant chunks, retrieve, making sums and compare them with the answers","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndef process_spanish_csv(file_path, output_path):\n    try:\n        print(f\"\\nProcessing file: {file_path}\")\n\n        df = pd.read_csv(file_path, encoding='utf-8', header=None)\n\n        main_column = df.apply(lambda row: \" \".join(row.dropna().astype(str)).strip(), axis=1)\n\n        main_column = main_column[main_column != \"\"]\n\n        print(f\"First 5 Rows of Consolidated Data:\\n{main_column.head()}\")\n\n        questions = []\n        answers = []\n        current_question = None\n\n        for text in main_column:\n            text = str(text).strip()  # Clean the text\n\n            if text.startswith(\"Pregunta:\"):\n                current_question = text.replace(\"Pregunta:\", \"\").strip()\n            elif text.startswith(\"Respuesta:\") and current_question:\n                answer = text.replace(\"Respuesta:\", \"\").strip()\n                questions.append(current_question)\n                answers.append(answer)\n                current_question = None  \n            else:\n                continue  \n\n        qa_df = pd.DataFrame({'Pregunta': questions, 'Respuesta': answers})\n\n        print(f\"Extracted DataFrame:\\n{qa_df.head()}\")\n\n        qa_df.to_csv(output_path, index=False, encoding='utf-8')\n        print(f\"Processed file saved to: {output_path}\")\n\n    except Exception as e:\n        print(f\"Error processing file {file_path}: {e}\")\n\nfile_paths = {\n    'gdpr': ('/kaggle/input/spanish-80-qa/q and a gdpr 80 spanish.csv', '/kaggle/working/consolidated_gdpr_spanish_pinecone.csv'),\n    'ai_act': ('/kaggle/input/spanish-80-qa/q and a spanish 80 ai.csv', '/kaggle/working/consolidated_ai_act_spanish_pinecone.csv'),\n    'dma': ('/kaggle/input/spanish-80-qa/questions_answers_digital_marketing es.csv', '/kaggle/working/consolidated_dma_spanish_pinecone.csv'),\n    'dsa': ('/kaggle/input/spanish-80-qa/questions_answers_digital_services es.csv', '/kaggle/working/consolidated_dsa_spanish_pinecone.csv'),\n}\n\nfor law, paths in file_paths.items():\n    input_path, output_path = paths\n    process_spanish_csv(input_path, output_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:56:33.374855Z","iopub.execute_input":"2024-12-05T16:56:33.375208Z","iopub.status.idle":"2024-12-05T16:56:33.539525Z","shell.execute_reply.started":"2024-12-05T16:56:33.375176Z","shell.execute_reply":"2024-12-05T16:56:33.538679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndef process_spanish_csv(file_path, output_path):\n    try:\n        print(f\"\\nProcessing file: {file_path}\")\n\n        df = pd.read_csv(file_path, encoding='utf-8', header=None)\n\n        main_column = df.apply(lambda row: \" \".join(row.dropna().astype(str)).strip(), axis=1)\n\n        main_column = main_column[main_column != \"\"]\n\n        print(f\"First 5 Rows of Consolidated Data:\\n{main_column.head()}\")\n\n        questions = []\n        answers = []\n        current_question = None\n\n        for text in main_column:\n            text = str(text).strip()  \n\n            if text.lower().startswith(\"pregunta\"):\n                current_question = text.split(\":\", 1)[-1].strip()\n            elif text.lower().startswith(\"respuesta\") and current_question:\n                answer = text.split(\":\", 1)[-1].strip()\n                questions.append(current_question)\n                answers.append(answer)\n                current_question = None  \n            else:\n                continue  \n\n        qa_df = pd.DataFrame({'Pregunta': questions, 'Respuesta': answers})\n\n        print(f\"Extracted DataFrame:\\n{qa_df.head()}\")\n\n        qa_df.to_csv(output_path, index=False, encoding='utf-8')\n        print(f\"Processed file saved to: {output_path}\")\n\n    except Exception as e:\n        print(f\"Error processing file {file_path}: {e}\")\n\n\nfile_paths = {\n    'gdpr': ('/kaggle/input/spanish-80-qa/q and a gdpr 80 spanish.csv', '/kaggle/working/consolidated_gdpr_spanish_pinecone.csv'),\n    'ai_act': ('/kaggle/input/spanish-80-qa/q and a spanish 80 ai.csv', '/kaggle/working/consolidated_ai_act_spanish_pinecone.csv'),\n    'dma': ('/kaggle/input/spanish-80-qa/questions_answers_digital_marketing es.csv', '/kaggle/working/consolidated_dma_spanish_pinecone.csv'),\n    'dsa': ('/kaggle/input/spanish-80-qa/questions_answers_digital_services es.csv', '/kaggle/working/consolidated_dsa_spanish_pinecone.csv'),\n}\n\nfor law, paths in file_paths.items():\n    input_path, output_path = paths\n    process_spanish_csv(input_path, output_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:56:38.780339Z","iopub.execute_input":"2024-12-05T16:56:38.780690Z","iopub.status.idle":"2024-12-05T16:56:38.900913Z","shell.execute_reply.started":"2024-12-05T16:56:38.780659Z","shell.execute_reply":"2024-12-05T16:56:38.899913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndef load_and_split_questions_answers(file_path):\n    df = pd.read_csv(file_path, encoding='utf-8', header=None)  \n    \n    questions = []\n    answers = []\n    \n    current_question = None  \n    \n    for index, row in df.iterrows():\n        text = row[0]  \n        \n        if pd.isna(text):\n            continue\n        \n        text = str(text).lstrip().replace('\\xa0', ' ')   \n\n        if text.startswith(\"Pregunta:\"):\n            current_question = text.replace(\"Pregunta:\", \"\").strip()\n        elif text.startswith(\"Respuesta:\") and current_question:\n            answer = text.replace(\"Respuesta:\", \"\").strip()\n            questions.append(current_question)\n            answers.append(answer)\n            current_question = None  \n    \n    qa_df = pd.DataFrame({'Pregunta': questions, 'Respuesta': answers})\n    \n    return qa_df\n\ncsv_paths = {\n    'gdpr': '/kaggle/working/consolidated_gdpr_spanish_pinecone.csv',\n    'ai_act': '/kaggle/working/consolidated_ai_act_spanish_pinecone.csv',\n    'dma': '/kaggle/working/consolidated_dma_spanish_pinecone.csv',\n    'dsa': '/kaggle/working/consolidated_dsa_spanish_pinecone.csv'\n}\n\nqa_dataframes = {}\n\nfor law, path in csv_paths.items():\n    qa_dataframes[law] = load_and_split_questions_answers(path)\n    print(f\"Processed {law.upper()} law:\")\n    print(qa_dataframes[law].head(), \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:56:43.231639Z","iopub.execute_input":"2024-12-05T16:56:43.232449Z","iopub.status.idle":"2024-12-05T16:56:43.279038Z","shell.execute_reply.started":"2024-12-05T16:56:43.232397Z","shell.execute_reply":"2024-12-05T16:56:43.278001Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport pinecone\nfrom transformers import pipeline\nfrom sentence_transformers import SentenceTransformer, util\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\nimport torch\n\n\nsummarizer = pipeline(\"summarization\", model=\"csebuetnlp/mT5_multilingual_XLSum\",device=-1)\ncosine_model = SentenceTransformer('dccuchile/bert-base-spanish-wwm-uncased', device='cpu')\nsemantic_model = SentenceTransformer('dccuchile/bert-base-spanish-wwm-cased', device='cpu')\n\ndef safe_truncate(text, max_tokens=1024):\n    tokens = tokenizer.tokenize(text)\n    if len(tokens) > max_tokens:\n        print(f\"Truncating text from {len(tokens)} to {max_tokens} tokens.\")\n        tokens = tokens[:max_tokens]\n    return tokenizer.convert_tokens_to_string(tokens)\n\ndef store_embeddings_in_pinecone(chunks, embeddings, namespace):\n    vectors = [\n        (f\"{namespace}_id_{i}\", embedding.tolist(), {\"text\": chunk})\n        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings))\n    ]\n    index.upsert(vectors=vectors, namespace=namespace)\n\ndef embed_and_query(query_text, model_norm, namespace, top_k=1):\n    try:\n        query_embedding = model_norm.encode([query_text])[0]\n        print(f\"Query embedding created for: {query_text}\")\n\n        results = index.query(\n            vector=query_embedding,\n            top_k=top_k,\n            namespace=namespace\n        )\n        return results\n    except Exception as e:\n        print(f\"Error querying Pinecone for namespace '{namespace}': {e}\")\n        return None\n        \ndef calculate_cosine_similarity(embedding1, embedding2):\n    return cosine_similarity([embedding1], [embedding2])[0][0]\n\ndef calculate_semantic_similarity(text1, text2):\n    embedding1 = semantic_model.encode(text1)\n    embedding2 = semantic_model.encode(text2)\n    return cosine_similarity([embedding1], [embedding2])[0][0]\n\ndef summarize_and_compare_all_laws(qa_dataframes, model_norm, namespaces):\n    similarities = {law: {'cosine': [], 'semantic': []} for law in namespaces.keys()}\n\n    for law, df in qa_dataframes.items():\n        print(f\"\\nProcessing summaries for {law.upper()} law:\")\n        question_col = 'Pregunta'\n        answer_col = 'Respuesta'\n\n        for _, row in df.iterrows():\n            question_text = row[question_col]\n            answer_text = row[answer_col]\n        \n            print(f\"Querying for: {question_text}\")\n            try:\n                results = embed_and_query(question_text, model_norm, namespaces[law], top_k=1)\n                if results and 'matches' in results and results['matches']:\n                    retrieved_chunk_id = results['matches'][0]['id']\n                if law in chunks_dict:\n                    retrieved_chunk_index = int(retrieved_chunk_id.split('_')[-1])\n                    retrieved_chunk = chunks_dict[law][retrieved_chunk_index]\n    \n                    print(f\"Retrieved chunk {retrieved_chunk_index} from {law.upper()}:\")\n                    print(retrieved_chunk)\n            \n            except Exception as e:\n                print(f\"Error processing question '{question_text}': {e}\")\n                continue\n\n        \n            truncated_text = safe_truncate(retrieved_chunk, max_tokens=1024)\n            try:\n                summary = summarizer(truncated_text, max_length=350, min_length=100, do_sample=False)[0]['summary_text']\n            except Exception as e:\n                print(f\"Failed to summarize chunk for question: {question_text}. Error: {e}\")\n                continue\n        \n            if summary:\n                print(f\"Original answer: {answer_text}\")\n                print(f\"Generated summary: {summary}\\n\")\n        \n                try:\n                    answer_embedding = model_norm.encode([answer_text])[0]\n                    summary_embedding = model_norm.encode([summary])[0]\n        \n                    cosine_sim = calculate_cosine_similarity(answer_embedding, summary_embedding)\n                    semantic_sim = calculate_semantic_similarity(answer_text, summary)\n        \n                    similarities[law]['cosine'].append(cosine_sim)\n                    similarities[law]['semantic'].append(semantic_sim)\n        \n                    print(f\"Cosine similarity: {cosine_sim:.4f}\")\n                    print(f\"Semantic similarity: {semantic_sim:.4f}\\n\")\n                except Exception as e:\n                    print(f\"Error calculating similarities for question: {question_text}. Error: {e}\")\n            else:\n                print(f\"Failed to summarize for: {question_text}\")\n\n    print(\"Calculated Averages:\")\n    for law in similarities:\n        cosine_scores = similarities[law]['cosine']\n        semantic_scores = similarities[law]['semantic']\n        if cosine_scores:\n            avg_cosine = sum(cosine_scores) / len(cosine_scores)\n            print(f\"{law.upper()} Average Cosine Similarity: {avg_cosine:.4f}\")\n        if semantic_scores:\n            avg_semantic = sum(semantic_scores) / len(semantic_scores)\n            print(f\"{law.upper()} Average Semantic Similarity: {avg_semantic:.4f}\")\n    return similarities\n\nqa_dataframes = {\n    'gdpr': pd.read_csv('/kaggle/working/consolidated_gdpr_spanish_pinecone.csv'),\n    'ai_act': pd.read_csv('/kaggle/working/consolidated_ai_act_spanish_pinecone.csv'),\n    'dma': pd.read_csv('/kaggle/working/consolidated_dma_spanish_pinecone.csv'),\n    'dsa': pd.read_csv('/kaggle/working/consolidated_dsa_spanish_pinecone.csv'),\n}\n\nfor law, df in qa_dataframes.items():\n    chunks = df['Respuesta'].tolist()\n    embeddings = cosine_model.encode(chunks)\n    store_embeddings_in_pinecone(chunks, embeddings, namespace=law)\n\nnamespaces = {law: law for law in qa_dataframes.keys()}\nsummarize_and_compare_all_laws(qa_dataframes, cosine_model, namespaces)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:56:46.558101Z","iopub.execute_input":"2024-12-05T16:56:46.558519Z","iopub.status.idle":"2024-12-05T18:38:44.489062Z","shell.execute_reply.started":"2024-12-05T16:56:46.558486Z","shell.execute_reply":"2024-12-05T18:38:44.488120Z"}},"outputs":[],"execution_count":null}]}